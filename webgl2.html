<!DOCTYPE html>
<meta charset="utf-8">
<!-- 
    https://jakedowns.github.io/starpages/webgl2.html
    > add bitonic sort to our todo list 
-->
<html>
<head>
    <title>WebGL Pixel Mixer - jakedowns</title>
    <script src="https://jakedowns.github.io/starpages/res/CCapture.all.min.js"></script>
    <style>
        html, body { margin: 0; padding: 0; overflow: hidden;  background-color: #000; }
        canvas { width: 100%; height: 100%; opacity: 0.1; filter: blur(100px); transition: filter 0.5s ease-in-out, opacity 0.5 ease-in-out; will-change: filter; }
        canvas.unblur { filter: blur(0px); opacity: 1; }
        canvas.undarken { opacity: 0.8; }
        .drop-here-text {
            pointer-events: none;
            position: absolute;
            left: 0; right: 0; top: 0; bottom: 0;
            z-index: 998;
            font-size: 43px;
            font-weight: bold;
            text-align: center;
            color: white;
            font-family: sans-serif;
            text-shadow: 4px 4px 5px black, 5px 5px 5px blue;
            -webkit-text-strokes: 1px black;
            top: 50%;
            transform: translateY(-50%);
            transition: all 1s ease-in-out;
        }
        .drop-here-text.fadeout {
            opacity: 0;
            pointer-events: none;
        }
        .drop-here-text span {
            display: block;
            font-size: 25px;
        }
        .drop-here-text.fadeout span {
            pointer-events: none;
        }
        .drop-here-text .hint {
            font-size: 15px;
        }
        .intro-video {
            top: 50%;
            position: absolute;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1000;
            display: block;
        }
        p {
            color: white;
        }
        .video-underlay {
            background-color: rgba(.1,0,.1,.8);
            backdrop-filter: blur(10px);
            position: absolute;
            z-index: 999;
            top: 0; left: 0; right: 0; bottom: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .hide-video-button {
            text-align: center;
            width: auto;
            margin: 0 auto;
            position: relative;
            display: block;
            border-radius: 100px;
            border: 2px solid black;
            padding: 10px;
            font-size: 20px;
            color: white;
            cursor: pointer;
            transition: all 1s ease-in-out;
            background-color: #663dff;
            
        }
        .hide-video-button:hover {
            background-color: #663dff;
            animation: gradient-animation 2s ease infinite; /* Apply the animation */
        }
        @keyframes gradient-animation {
            0%, 100% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            /* 100% {
                background-position: 0% 50%;
            } */
        }

        .hide-video-button {
            background-size: 200% 200%; /* Extend the background size for the animation */
            background-image: linear-gradient(319deg, #663dff 0%, #aa00ff 37%, #cc4499 100%);
            animation: gradient-animation 3s ease infinite; /* Apply the animation */
        }

        #imageLoader {
            position: absolute;
            right: 0; bottom: 10px;
            z-index: 1001;
            cursor: pointer;
        }

    </style>
</head>
<body>
    <!-- view source on github -->
    <a href="https://github.com/jakedowns/starpages/blob/main/webgl2.html" target="_blank" style="position: absolute; top: 0; right: 0; z-index: 1000; font-size: 10px; font-family: sans-serif; color: white; text-decoration: none; padding: 5px; background-color: black; opacity: 0.5;">view source on GitHub</a>

    <!-- buy me a coffee; ko-fi link -->
    <a href="https://ko-fi.com/jakedowns" target="_blank" style="position: absolute; top: 0; left: 0; z-index: 1000; font-size: 10px; font-family: sans-serif; color: white; text-decoration: none; padding: 5px; background-color: black; opacity: 0.5;">‚òïü•∞ Buy me a coffee</a>

    <input type="file" id="imageLoader" name="imageLoader" style="position: absolute;"/>

    <div class="intro-video">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/NGA-Sc-2XTg?si=YxW01ggV4KRXI-U4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        <p>NOTE: this only works on Windows + Chrome. I have not tested Android, and it is broken on MacOS/iOS (i dont know why, if you think you do, please reach out)</p>
        <p>‚ö†Ô∏è Flashing Light Warning ‚ö†Ô∏è <br/>this app produces rapidly flashing light patterns. I'm working on a "safe" comfort mode - but for now, do not use it if you are photo-sensitive. üôáüèª‚Äç‚ôÇÔ∏èüôèüèª</p>
        <span class="hide-video-button" onclick="window.hideVideo()">Click to Continue... &gt;</span>
    </div>

    <div class="video-underlay" onclick="window.hideVideo()"></div>

    <div class="drop-here-text">webgl pixel mixer<span>drop an image here<br/>or<br/>tap here to select an image <span class="hint">(local only, doesn't get uploaded anywhere)</span></span></div>
    <canvas id="glCanvas"></canvas>
    <script>
        window.uReflectionY = 0.5; // 0.5 = no reflection, 0 = full reflection, 1 = no reflection
        window.reverseSort = true;
        window.capturer = null;
        window.capturing = false;
        window.capturedFrames = 0;    
        
        window.selectedImageTexture;
        
        window.hideVideo = function(){
            document.querySelector(".intro-video").style.display = "none";
            document.querySelector(".video-underlay").style.display = "none";
        }
        window.startCapture = function(){
            if(!window.capturer){
                console.warn("capturer not initialized");
                return;
            }
            window.capturing = true;
            window.capturedFrames = 0;
            window.capturer.start();
            render();
        }
        window.stopCapture = function(){
            if(!window.capturer){
                console.warn("capturer not initialized");
                return;
            }
            window.capturing = false;
            window.capturer.stop();
            window.capturer.save();
        }
        // fsshader fragment shader source frag shader here fshader

        let fsSource = `
precision mediump float;
uniform vec2 uResolution;
uniform float uTime;
uniform sampler2D uBaseTexture;
uniform sampler2D uOriginalPixelDataTexture;
uniform sampler2D uOffsetTexture;
uniform sampler2D uSelectedImageTexture;
uniform float uSwirlTurns;
uniform float uSwirlAmp;
vec2 center = vec2(0.5, 0.5); // Center of the swirl, usually the middle of the texture
uniform int uMode;
uniform int uPxDensity;

uniform float uReflectionX;
uniform float uReflectionY;

uniform float uScrollOffsetYSpeed;
uniform float uScrollOffsetXSpeed;

float PI = 3.1415926535897932384626433832795;

uniform int uSortOffset;
uniform int uSortStepSize;

vec2 corrected;

vec2 applySwirl(vec2 uv, float uSwirlTurns, float uSwirlAmp, vec2 center) {
    // Translate UV coordinates so that the center of the swirl is at (0,0)
    vec2 offset = uv - center;

    // Calculate the distance from the center
    float distance = length(offset);

    // Calculate the angle for the swirl
    float angle = uSwirlTurns * 2.0 * PI * distance;
    float scale = 1.5;

    // Adjust the angle based on the swirl amplitude
    if (uSwirlAmp < 0.5) {
        // Decay the spiral
        angle *= mix(1.0, 0.0, (0.5 - uSwirlAmp) * scale);
    } else {
        // Accelerate the spiral's divergence
        angle *= mix(1.0, 2.0, (uSwirlAmp - 0.5) * scale);
    }

    // remap the range from 0.0 - 1.0 to 0.0 - 0.5
    angle *= 0.5;

    // Rotate the coordinates
    mat2 rotation = mat2(cos(angle), -sin(angle), sin(angle), cos(angle));
    uv = center + rotation * offset;

    return uv;
}

void main() {
    // gl_FragColor = vec4(0.0,1.0,0.0,1.0);
    // return;

    // adjust for pixel density
    corrected = gl_FragCoord.xy / (uResolution * float(uPxDensity));
    // adjust for aspect ratio to square pixels
    //corrected.x *= uResolution.x / uResolution.y;

    // adjust center for aspect ratio to square pixels
    //center.x *= uResolution.x / uResolution.y;

    // apply swirl
    corrected = applySwirl(corrected, uSwirlTurns, uSwirlAmp, center);

    // scroll offset based on uScrollOffsetYSpeed
    corrected.y += uTime * uScrollOffsetYSpeed; // * 0.01;
    // wrap around
    corrected.y = mod(corrected.y, 1.0);

    // and X
    corrected.x += uTime * uScrollOffsetXSpeed; // * 0.01;
    // wrap around
    corrected.x = mod(corrected.x, 1.0);

    // if uSortOffset > 0, we need to check if _this_ pixel's corresponding index
    // falls within uSortStepSize worth of pixels as expressed in a 1D array of rgba values
    // if so, we need to return yellow
    // int numPixels = int(uResolution.x * uResolution.y);
    int correctedNumPixels = int(uResolution.x * uResolution.y) / uPxDensity;
    int correctedSortOffset = uSortOffset; // / uPxDensity;
    int correctedSortStepSize = uSortStepSize; // / uPxDensity;
    if(correctedSortOffset > 0){
        // we need to check if this pixel's corresponding index falls within the sort window
        // if so, we need to return yellow
        int correctedPixelIndex = int(corrected.y * uResolution.x + corrected.x);
        if(correctedPixelIndex >= correctedSortOffset && correctedPixelIndex < correctedSortOffset + correctedSortStepSize){
            gl_FragColor = vec4(1.0,1.0,0.0,1.0);
            return;
        }
    }
    
    if(uMode == 1){
        // default mode: use the offset texture's [r]ed channel to offset our uv/xy[x] lookup in the OPPPOSITE direction
        // and use offset texture's [g]reen channel to offset our uv/xy[y] lookup in the OPPPOSITE direction
        
        vec4 offsetData = texture2D(uOffsetTexture, corrected);
        vec2 offsetCoords = corrected;
        offsetCoords.x += offsetData.r;
        offsetCoords.y += offsetData.g;
        // Apply the swirl
        //offsetCoords = applySwirl(offsetCoords, uSwirlTurns, uSwirlAmp, center);

        gl_FragColor = texture2D(uOriginalPixelDataTexture, offsetCoords);
        // constrain r,g,b to 0.0 - 1.0
        gl_FragColor.r = clamp(gl_FragColor.r, 0.0, 1.0);
        gl_FragColor.g = clamp(gl_FragColor.g, 0.0, 1.0);
        gl_FragColor.b = clamp(gl_FragColor.b, 0.0, 1.0);
        
    }else if(uMode == 2){
        // ramp between "magma" dark black, purple, yellow, and white
        // based on the magnitude of sample r and g channels: texture2D(uOffsetTexture, corrected)
        vec4 black = vec4(0.0,0.0,0.0,1.0);
        vec4 purple = vec4(0.5,0.0,0.5,1.0);
        vec4 magenta = vec4(1.0,0.0,1.0,1.0);
        vec4 yellow = vec4(1.0,1.0,0.0,1.0);
        vec4 white = vec4(1.0,1.0,1.0,1.0);

        // 1. sample offset texture's r and g channels
        vec4 sample = texture2D(uOffsetTexture, corrected);

        // 2. calculate magnitude of r and g channels
        float magnitude = sqrt(sample.r * sample.r + sample.g * sample.g);

        // 3. lerp from base texture towards "target" offset texture
        // Corrected the nested mix functions
        vec4 gradientSample = mix(black, 
                                mix(purple, 
                                    mix(magenta, 
                                        mix(yellow, white, magnitude), 
                                    magnitude),
                                magnitude),
                            magnitude);

        // 4. set the fragment color
        gl_FragColor = gradientSample;
    }else if(uMode == 3){
        gl_FragColor = texture2D(uBaseTexture, corrected);    
    }else if(uMode == 4){
        // debug sample uSelectedImageTexture
        gl_FragColor = texture2D(uSelectedImageTexture, corrected);
    }else{
        // fallback mode
        // debug sample unmodified base texture
        gl_FragColor = texture2D(uOriginalPixelDataTexture, corrected);    
    }
    // make sure our alpha channel is 1.0
    gl_FragColor.a = 1.0; //clamp(gl_FragColor.a, 0.1, 1.0);
}
        `;

    // bare bones debug
    // make sure we set, otherwise safari won't work
//     fsSource = `
// precision mediump float;
// void main() {
//     gl_FragColor = vec4(1.0,0.0,0.0,1.0);
// }
// `

        
        // note: we've bound the outputSurfacePositionBuffer to the vertex shader's "aVertexPosition" attribute
        // we've bound the offset texture to the fragment shader's "uOffsetTexture" uniform
        // and, critically, we've bound the offset texture to texture unit 0 (gl.TEXTURE0)
        // currently, the vertex shader does nothing, since we need a highly subdivided mesh to see the effect of the offset texture
        // so for now, we're using a simple "pass-through" vertex shader, which simply passes the vertex position to the fragment shader

        let frameCount = 0;
        let seed = 0;
        let MODE = 1;
        let _pixel_density = 4; //6 // larger = LARGER pixels, smaller = smaller (FASTER, LOWER REZ), 1:1 pixel ratio (SLOWER, HIGH REZ)
        let _max_step_sort_size = 1e5 * 2;
        Object.defineProperty(window, "pixel_density", {
            get: function(){
                return _pixel_density;
            },
            set: function(value){
                _pixel_density = value;
                resizeCanvas();
            }
        });
        Object.defineProperty(window, "MAX_SORT_STEP_SIZE", {
            get: function(){
                return _max_step_sort_size; // Math.floor(canvas.width / pixel_density) * Math.floor(canvas.height / pixel_density);
            },
            set: function(value){
                _max_step_sort_size = value;
                current_sortStepSize = value;
                sortStepSize = value;
            }
        })

        let then = 0;
        let canvas, gl;
        let outputSurfacePositionBuffer;
        let offsetTexture, baseTexture, originalPixelDataTexture;
        let lerpedColorTexture;
        let uSwirlAmp = 1.0, uSwirlTurns = 3.0;
        let shaderProgram, programInfo;
        let pixel_positions = [];
        let pixelData, originalPixelData, latestPixelDataSnapshot;
        const bytesPerPixel = 4; // For RGBA format

        window.recenterMouseRefValue = function(){
            mouseX=window.innerWidth/2;mouseY=window.innerHeight/2
        }

        // domready
        function onReady(){
            try{
                // Create a capturer that exports a WebM video
                var isWebMSupported = document.createElement('video').canPlayType('video/webm; codecs="vp8, vorbis"');
                var motionBlurFrames = 0;//2;
                capturer = isWebMSupported 
                ? new CCapture( { 
                    format: 'webm', 
                    motionBlurFrames,
                    verbose: false, 
                    fps: 120 
                } ) 
                : new CCapture( { 
                    format: 'png', 
                    motionBlurFrames,
                    verbose: false, 
                    framerate: 120 
                } );
            }catch(e){
                console.error('failed to create capturer',e);
            }

            // if(!confirm('this demo produces flashing lights, are you sure you want to continue?')){
            //     return;
            // }

            // if we're on a mobile device, change .drop-here-text > span to say "tap here to select an image <span class="hint">(local only, doesnt get uploaded anywhere)</span>"
            //if(/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)){
                let match = document.getElementsByClassName('drop-here-text');
                if(!match.length){
                    throw new Error("no .drop-here-text element found");
                }
                if (match.length > 0) {
                    console.warn('match',match)
                    // Array.from(match).forEach((el) => {
                    //     el.innerHTML = '';
                    // });
                    match[0].style.pointerEvents = 'auto';
                    match[0].addEventListener('click',async(e)=>{

                        if(document.querySelector('canvas')?.classList?.contains('unblur')){
                            return;
                        }

                        document.querySelector('canvas')?.classList?.add('undarken');
                        let input = document.createElement('input');
                        input.type = 'file';
                        input.accept = 'image/*';
                        hideIntroText();
                        input.onchange = async(e)=>{
                            let file = e.target.files[0];
                            console.warn(file);

                            // get a blob for the file
                            let blob = await file.arrayBuffer();
                            blob = new Blob([blob], {type: file.type});
                            console.warn(blob);

                            let b64 = await imageBlobToBase64(blob);
                            console.warn({blob_as_b64:b64})
                            await loadImageAsTexture(b64);

                            
                        }
                        input.click();
                    });

                    match[0].addEventListener("drop", onImageDrop);
                    match[0].addEventListener("dragover", function(event) { event.preventDefault(); });
                }
            //}
            
            
            // WebGL context setup
            canvas = document.getElementById('glCanvas');
            canvas.addEventListener("drop", onImageDrop);
            canvas.addEventListener("dragover", function(event) { event.preventDefault(); });
            
            gl = canvas.getContext('webgl');

            if (!gl) {
                //console.error('Unable to initialize WebGL. Your browser may not support it.');
                return;
            }
            // prepares:
            // outputSurfacePositionBuffer, 
            onGLReady();      
            
            loadImageAsTexture("./res/Screen-interface-design-Bill-Atkinson-Susan-Kare-1983.webp");
            

            requestAnimationFrame(render);

            
        }

        window.addEventListener("resize", ()=>{
            // onResize
            resizeCanvas();
            // todo: they sould grow and shrink dynamically...
            initializePositionsAndOffsetData(keepPixelData = true);
        });

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            fixedPixelsX = Math.floor(canvas.width/pixel_density);
            fixedPixelsY = Math.floor(canvas.height/pixel_density);
            window.DID_BIND_BASE_SINCE_RESIZE = false;
            if(gl){
                try{
                    gl.viewport(0, 0, canvas.width, canvas.height);
                    // gl.bindTexture(gl.TEXTURE_2D, baseTexture);
                    gl.useProgram(programInfo.program);
                    gl.uniform2f(programInfo.uniformLocations.uResolution, Math.floor(canvas.width/pixel_density), Math.floor(canvas.height/pixel_density));
                }catch(e){
                    console.error("Error resizing canvas",e);
                }
            }
        }

        // two triangles that cover the entire screen
        // our display surface positions, not our inner "pixel" positions
        const output_surface_positions = [
            -1, -1,
            1, -1,
            -1, 1,
            -1, 1,
            1, -1,
            1, 1,
        ];

        // CPU outputSurfacePositionBuffer (output_surface_positions) mirrors to the GPU "offset texture":
        // these "positional" offsets are used as "Target" x, y values
        // and the fragment shader uses these "target" values, 
        // and lerps the "current" value _towards_ 
        // the "target" value over a parameterized duration of time
        // offsetTexture: [screenWidth x screenHeight] (rgba); where r = x offset, and g = y offset | b,a are unused for now

        // we artificially delay the sorting algo. to help visualize the sorting process
        // we then show how parallelism can be used to speed up the sorting process (bitonic sort) + realtime "accumulation" of the sorted values (similar to Raytracing stochastic accumulation)
        let numPixels = 0;
        let fixedPixelsX,fixedPixelsY;
        function initializePositionsAndOffsetData(keepPixelData = true) {
            // if(typeof outputSurfacePositionBuffer == "undefined"){
            //     //throw new Error("outputSurfacePositionBuffer is undefined");
            //     console.error("outputSurfacePositionBuffer is undefined");
            //     return;
            // }
            
            // Update buffers with new data
            gl.bindBuffer(gl.ARRAY_BUFFER, outputSurfacePositionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, output_surface_positions, gl.DYNAMIC_DRAW);
            
            //console.warn("Initializing output_surface_positions and pixel data");

            
            
            numPixels = canvas.width * canvas.height;
            numPixels = Math.floor(numPixels / pixel_density);

            // error if not divisible by 4
            // if(numPixels % 4 !== 0){
            //     console.error("numPixels must be divisible by 4");
            //     return;
            // }
            // // error if not divisible by 2
            // if(numPixels % 2 !== 0){
            //     console.error("numPixels must be divisible by 2");
            //     return;
            // }

            if(!keepPixelData){
                pixel_positions = [];
                pixelData = undefined;
            }

            // if `pixel_positions` is empty or undefined, we need to initialize it
            // otherwise, we need to determine to grow or shrink it
            if(typeof pixel_positions === "undefined" || !pixel_positions.length){
                pixel_positions = new Float32Array(numPixels * 2); // x, y for each pixel
            }else{
                // shrink || grow
                // if we're shrinking, we need to truncate the array
                // if we're growing, we need to pad the array
                if(pixel_positions.length > numPixels * 2){
                    // truncate
                    pixel_positions = pixel_positions.slice(0,numPixels * 2);
                }else if(pixel_positions.length < numPixels * 2){
                    // pad
                    let new_pixel_positions = new Float32Array(numPixels * 2);
                    new_pixel_positions.set(pixel_positions);
                    pixel_positions = new_pixel_positions;
                }
            }

            resetOffsetTexture();
            if(typeof pixelData === "undefined" || !pixelData.length){
                pixelData = new Uint8Array(numPixels * bytesPerPixel); // RGBA for each pixel

                // Initialize position and pixel data
                for (let y = 0; y < fixedPixelsY; y++) {
                    for (let x = 0; x < fixedPixelsX; x++) {
                        const index = (y * fixedPixelsX + x) * 2;
                        const pixelIndex = (y * fixedPixelsX + x) * bytesPerPixel;

                        // Set position (x, y)
                        pixel_positions[index] = (x / fixedPixelsX) * 2 - 1; // Convert to clip space
                        pixel_positions[index + 1] = (y / fixedPixelsY) * 2 - 1; // Convert to clip space

                        // Initialize pixel data with random colors
                        pixelData[pixelIndex] = Math.floor(Math.random() * 256); // R
                        pixelData[pixelIndex + 1] = Math.floor(Math.random() * 256); // G
                        pixelData[pixelIndex + 2] = Math.floor(Math.random() * 256); // B
                        pixelData[pixelIndex + 3] = Math.floor(Math.random() * 256); // Alpha
                    }
                }

                // Update buffers with new data
                // gl.bindBuffer(gl.ARRAY_BUFFER, pixelPositionsBuffer);
                // gl.bufferData(gl.ARRAY_BUFFER, pixel_positions, gl.DYNAMIC_DRAW);
    
                // bind the base texture to our initial pixel data ( a frozen snapshot of the initial state of the pixels for our lerping algo. to work with )
                gl.bindTexture(gl.TEXTURE_2D, baseTexture);
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixelData);

            }else{
                // grow or shrink pixelData
                if(pixelData.length > numPixels * bytesPerPixel){
                    // truncate
                    pixelData = pixelData.slice(0,numPixels * bytesPerPixel);
                }else if(pixelData.length < numPixels * bytesPerPixel){
                    // pad
                    let new_pixelData = new Uint8Array(numPixels * bytesPerPixel);
                    new_pixelData.set(pixelData);
                    pixelData = new_pixelData;
                }
            }
            

            // gl.bindTexture(gl.TEXTURE_2D, offsetTexture);

            // // Only use R and G channels, force A channel to 1
            // let offsetPixelData = pixelData.map((value, index) => {
            //     if (index === 3) {
            //         return 255; // full alpha
            //     }
            //     if (index === 2) {
            //         // average of R and G channels
            //         return (pixelData[index - 2] + pixelData[index - 1]) / 2;
            //     }
            //     return value;
            // });

            // gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, offsetPixelData);

            // Bind the output position buffer.
            gl.bindBuffer(gl.ARRAY_BUFFER, outputSurfacePositionBuffer);

            // Tell WebGL how to pull out the positions from the 
            // outputSurfacePositionBuffer into the vertexPosition attribute called "aVertexPosition"
            // note: it WAS reading rg as xy, but now we're going back to an array of float pairs
            {
                const numComponents = 2;  // pull out 2 values per iteration
                const type = gl.FLOAT;    // the data in the buffer is 32bit floats
                const normalize = false;  // don't normalize
                const stride = 0;         // how many bytes to get from one set to the next
                const offset = 0;         // how many bytes inside the buffer to start from
                gl.vertexAttribPointer(
                    programInfo.attribLocations.vertexPosition,
                    numComponents,
                    type,
                    normalize,
                    stride,
                    offset);
                gl.enableVertexAttribArray(
                    programInfo.attribLocations.vertexPosition);
            }
        }

        function rgbToHsv(color){
            let r = color[0] / 255;
            let g = color[1] / 255;
            let b = color[2] / 255;
            let max = Math.max(r, g, b), min = Math.min(r, g, b);
            let h, s, v = max;
        
            let d = max - min;
            s = max == 0 ? 0 : d / max;
        
            if (max == min) {
                h = 0; // achromatic
            } else {
                switch (max) {
                    case r: h = (g - b) / d + (g < b ? 6 : 0); break;
                    case g: h = (b - r) / d + 2; break;
                    case b: h = (r - g) / d + 4; break;
                }
        
                h /= 6;
            }
        
            return [ h, s, v ];
        }

        let swapped = false;
        let DID_COMPLETE_SORT_SINCE_RESET = false;
        // current sorting offset
        // we pass this to our fragment shader 
        // so we can color the pixels that are currently being sorted
        // we also pass the window width, so we can color the pixels that are being compared
        let sortOffset = 0;
        window.sortStepSize = 10e5; //-1; //10e3; // Number of elements to sort per call, adjust as needed
        window.current_sortStepSize = window.sortStepSize;

        function resetOffsetTexture(erasePixelData = false){
            // reset offset texture to all 0s with 255 for alpha channel
            let zeros = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
            zeros = zeros.map((value, index) => {
                if (index === 3) {
                    return 255;
                }
                return value;
            });
            gl.bindTexture(gl.TEXTURE_2D, offsetTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, zeros);

            if(erasePixelData){
                // reset pixel data to all 0s
                pixelData = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
            }
        }

        function newCheck(inner_i, currentColor, currentHSV, nextColor, nextHSV){
            let swapped = 0;
            let rankA = 0; // should we swap?
            let rankB = 0;
            rankA += currentHSV[0] > nextHSV[0] ? 1 : 0;
            rankB += currentHSV[0] < nextHSV[0] ? 1 : 0;

            rankA += currentHSV[1] > nextHSV[1] ? 1 : 0;
            rankB += currentHSV[1] < nextHSV[1] ? 1 : 0;

            rankA += currentHSV[2] > nextHSV[2] ? 1 : 0;
            rankB += currentHSV[2] < nextHSV[2] ? 1 : 0;

            rankA *= currentColor[3]/255; // account for alpha
            rankB *= nextColor[3]/255; // account for alpha

            //console.warn({rankA,rankB})

            // old:
            //if(rankA > rankB){

            // new: epsilon-based approach
            if(rankA > rankB + Math.random()*0.001){
                // Swap colors in pixel data
                [pixelData[inner_i * bytesPerPixel], pixelData[(inner_i + 1) * bytesPerPixel]] = [pixelData[(inner_i + 1) * bytesPerPixel], pixelData[inner_i * bytesPerPixel]];
                [pixelData[inner_i * bytesPerPixel + 1], pixelData[(inner_i + 1) * bytesPerPixel + 1]] = [pixelData[(inner_i + 1) * bytesPerPixel + 1], pixelData[inner_i * bytesPerPixel + 1]];
                [pixelData[inner_i * bytesPerPixel + 2], pixelData[(inner_i + 1) * bytesPerPixel + 2]] = [pixelData[(inner_i + 1) * bytesPerPixel + 2], pixelData[inner_i * bytesPerPixel + 2]];

                // NOTE: we don't swap, we're going to just update our pixelData using r to represent x offset, and g to represent y offset
                // we'll use the fragment shader to do the actual swapping
                // use our fixedPixelsX to account for row/column wrapping in this x/y calculation
                // we're visually how far the pixel has moved in terms of 1D array indexes, from it's original position to it's sorted position over time
                // we're going to be additively writing incremental changes as brightness adjustments to the offset texture
                // negative when we need to move left/up, positive when we need to move right/down
                // keeping in mind that we're accounting for going from 1D array space to 2D screen space as though the array were laid out in a rasterized pattern
                let x_offset = (inner_i + 1) % fixedPixelsX - inner_i % fixedPixelsX;
                let y_offset = Math.floor((inner_i + 1) / fixedPixelsX) - Math.floor(inner_i / fixedPixelsX);

                // make the offset a fixed value from 0 - 0.1
                x_offset = Math.sign(x_offset) * 0.1;
                y_offset = Math.sign(y_offset) * 0.1;

                // NOTE: given how array shifting works, we need to "write" an additive value to the offset texture for each intermediary pixel between the two pixels we're swapping
                // nice thing about this algo is, it's bitwise, so we can do it in parallel, AND there's no interviening pixels, so we don't have to account for it with our current sort algo
                pixelData[inner_i * bytesPerPixel] += x_offset;
                pixelData[inner_i * bytesPerPixel + 1] += y_offset;
                // empty green channel
                pixelData[inner_i * bytesPerPixel + 2] = 0;

                swapped = true;
            }
            return swapped;
        }

        let noSwapStreak = 0; // Track consecutive passes without swaps
        let prevDidSwap = false; // Track whether a swap occurred in the previous pass

        function finalSortPass() {
            sortStepSize = 1; // Set window size to minimum
            applyBubbleSortStep(); // Perform final sort pass
        }

        function isOverlookingPixels() {
            // Implement logic to check for consistently overlooked pixels
            // This could be a heuristic based on tracking which pixels haven't moved in several passes
            // or it could be a heuristic based on the number of pixels that have moved in the last pass
            
            return false; // Placeholder return
        }

        /** 
         * return true if swapped
         * */
        function applyBubbleSortStep() {
            //console.warn("Applying bubble sort step");
            // Apply one step of the bubble sort algorithm
            swapped = false;

            let crossedCycleBoundaryThisPass = false;

            const numPixels = fixedPixelsX * fixedPixelsY;
            let _sortStepSize = window.sortStepSize === -1 ? numPixels : window.sortStepSize;

            if (window.sortStepSize === -1) {
                let scale;
                if (numPixels < 1e5) {
                    // do multiple passes per frame when the image is small enough to fit into a single pass
                    scale = 1e5 / numPixels;
                } else {
                    // break into smaller chunks for large images
                    scale = numPixels / 1e5;
                }
                _sortStepSize = numPixels * scale; // Adjusting for pixel density
            }
            window.current_sortStepSize = _sortStepSize;
            
            // if _sortStepSize is > than the size of threads on our GPU, we need to break it up into multiple passes

            // Calculate the end of the current sorting window
            //const windowEnd = Math.min(sortOffset + _sortStepSize, numPixels - 1);
            const windowEnd = Math.max(0, sortOffset + _sortStepSize);

            // NOTE: there's a bug where if the offset is too large, we always wrap around before reaching the end of the base texture
            // we need to detect when this might happen and apply a correction to the window size to make sure that the whole texture is sorted
            // NOTE sortOffset is dynamic, and windowEnd is dynamic, so,
            // our heuristic to check if we might've overlooked pixels is defined as:
            // 

            // Update the sorting offset
            sortOffset += _sortStepSize;
            crossedCycleBoundaryThisPass = false;
            if (sortOffset >= numPixels) {
                crossedCycleBoundaryThisPass = true;
                // wrap around
                sortOffset = sortOffset % numPixels;
                // if we didnt swap this pass, 
                if(!prevDidSwap && !swapped){
                    // note we attribute multiple passes without swaps to the same cycle
                    noSwapStreak += Math.floor(((sortOffset % numPixels) / numPixels));
                }
            }

            for (let i = sortOffset; i < windowEnd - 1; i++) {
                let inner_i = i
                // if inner_i has gone out of bounds, we need to wrap it around
                if(inner_i >= numPixels){
                    inner_i = inner_i % numPixels;
                }
                const currentColor = pixelData.subarray(inner_i * bytesPerPixel, (inner_i + 1) * bytesPerPixel);
                const nextColor = pixelData.subarray((inner_i + 1) * bytesPerPixel, (inner_i + 2) * bytesPerPixel);

                let a_larger = (
                    currentColor[0] 
                    + currentColor[1] 
                    + currentColor[2] 
                    > 
                    nextColor[0] 
                    + nextColor[1] 
                    + nextColor[2]
                ) ? 1 : 0;

                if(window.reverseSort){
                    a_larger = !a_larger;
                }

                // Compare colors based on the sum of RGB values
                if (
                    a_larger
                ) {
                    // Swap colors in pixel data
                    [pixelData[inner_i * bytesPerPixel], pixelData[(inner_i + 1) * bytesPerPixel]] = [pixelData[(inner_i + 1) * bytesPerPixel], pixelData[inner_i * bytesPerPixel]];
                    [pixelData[inner_i * bytesPerPixel + 1], pixelData[(inner_i + 1) * bytesPerPixel + 1]] = [pixelData[(inner_i + 1) * bytesPerPixel + 1], pixelData[inner_i * bytesPerPixel + 1]];
                    [pixelData[inner_i * bytesPerPixel + 2], pixelData[(inner_i + 1) * bytesPerPixel + 2]] = [pixelData[(inner_i + 1) * bytesPerPixel + 2], pixelData[inner_i * bytesPerPixel + 2]];
                    swapped = true;
                }

                // convert to hsb , sort by hue, then value, then saturation
                // const currentHSV = rgbToHsv(currentColor);
                // const nextHSV = rgbToHsv(nextColor);
                // if(newCheck(inner_i, currentColor, currentHSV, nextColor, nextHSV)){
                //     swapped = true;
                // }
            }

            
            
            if (swapped) {
                // If a swap occurred, update the texture
                gl.bindTexture(gl.TEXTURE_2D, offsetTexture);
                // TODO: determine which bounding box DID change, and only update that region...
                gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, fixedPixelsX, fixedPixelsY, gl.RGBA, gl.UNSIGNED_BYTE, pixelData);
            }

            // if we've somehow gone negative, flip positive and clamp to 0
            if(sortOffset < 0){
                throw new Error("sortOffset is negative");
            }

            prevDidSwap = swapped;

            return swapped;
        }
        // for now we just pass-thru
        // later when we add sub-divided mesh, we'll need to use a vertex shader
        const vsSource = `
attribute vec4 aVertexPosition;
void main() {
gl_Position = aVertexPosition;
}
        `;
        // samples from uBaseTexture and uOffsetTexture
        

        function initShaderProgram(gl, vsSource, fsSource) {
            console.warn('[Debug] initShaderProgram',{gl,vsSource,fsSource});
            const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource);
            const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);

            const shaderProgram = gl.createProgram();
            gl.attachShader(shaderProgram, vertexShader);
            gl.attachShader(shaderProgram, fragmentShader);
            gl.linkProgram(shaderProgram);

            if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
                console.error('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
                return null;
            }

            console.warn("LINK STATUS:",gl.getProgramParameter(shaderProgram, gl.LINK_STATUS));

            // if there are ANY gl errors, re-throw the error
            const error = gl.getError();
            if (error !== gl.NO_ERROR) {
                //throw new Error('WebGL Error: ' + error);
                console.error('WebGL Error: ', error);
            }

            return shaderProgram;
        }

        function loadShader(gl, type, source) {
            console.warn('loadShader',{gl,type,source})
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);

            // if there are ANY gl errors, re-throw the error
            const error = gl.getError();
            if (error !== gl.NO_ERROR) {
                //throw new Error('WebGL Error: ' + error);
                console.error('WebGL Error: ', error);
            }

            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }

            return shader;
        }
        
        function preloadShaders(){
            shaderProgram = initShaderProgram(gl, vsSource, fsSource);
            // After initializing the shader program
            programInfo = {
                program: shaderProgram,
                attribLocations: {
                    vertexPosition: gl.getAttribLocation(shaderProgram, 'aVertexPosition'),
                },
                uniformLocations: {
                    uMode: gl.getUniformLocation(shaderProgram, 'uMode'),
                    uTime: gl.getUniformLocation(shaderProgram, 'uTime'),
                    uPxDensity: gl.getUniformLocation(shaderProgram, 'uPxDensity'),
                    uResolution: gl.getUniformLocation(shaderProgram, 'uResolution'),
                    uOffsetTexture: gl.getUniformLocation(shaderProgram, 'uOffsetTexture'),
                    uBaseTexture: gl.getUniformLocation(shaderProgram, 'uBaseTexture'),
                    uOriginalPixelDataTexture: gl.getUniformLocation(shaderProgram, 'uOriginalPixelDataTexture'),
                    //uniform float uSwirlTurns;
                    uSwirlTurns: gl.getUniformLocation(shaderProgram, 'uSwirlTurns'),
                    // uniform float uSwirlAmp;
                    uSwirlAmp: gl.getUniformLocation(shaderProgram, 'uSwirlAmp'),

                    uScrollOffsetYSpeed: gl.getUniformLocation(shaderProgram, 'uScrollOffsetYSpeed'),
                    uScrollOffsetXSpeed: gl.getUniformLocation(shaderProgram, 'uScrollOffsetXSpeed'),

                    //uPixelPositions: gl.getUniformLocation(shaderProgram, 'uPixelPositions'),

                    uSortOffset: gl.getUniformLocation(shaderProgram, 'uSortOffset'),
                    uSortStepSize: gl.getUniformLocation(shaderProgram, 'uSortStepSize'),

                    uReflectionX: gl.getUniformLocation(shaderProgram, 'uReflectionX'),
                    uReflectionY: gl.getUniformLocation(shaderProgram, 'uReflectionY'),
                },
            };
        }

        function readyDisplaySurface(){
            // Create and bind the position buffer
            outputSurfacePositionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, outputSurfacePositionBuffer);

            // go ahead and pop our initial data into the position buffer
            // we'll update it later
            //gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(output_surface_positions), gl.DYNAMIC_DRAW);
        }

        function setupTextures(){
            // our initial pixel data
            // random noise for now, but we're going to add drag-and-drop later
            
            baseTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, baseTexture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

            // clone into originalPixelDataTexture
            originalPixelDataTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, originalPixelDataTexture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
            

            // Create and bind the offset texture
            // where we track position offsets for each pixel
            // from their unsorted initial positions to their sorted final positions
            offsetTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, offsetTexture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

            // our output texture is actually a separate buffer where
            // we lerp _it_ towards the base texture
            // continually saving it's derrived value back to lerpedColorTexture so that,
            // we can use lerpedColorTexture as our input texture for the next frame
            lerpedColorTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, lerpedColorTexture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            //gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            //gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        }

        function onGLReady(){
            console.log("Initializing WebGL");

            preloadShaders();
            readyDisplaySurface();
            setupTextures();

            // @requires gl, canvas
            // faux "init" resize for updating to initial window size
            resizeCanvas();

            // @requires outputSurfacePositionBuffer
            initializePositionsAndOffsetData();

            
        }
        window.do_sort = 1;
        // Draw the scene repeatedly
        function render(now) {
            const deltaTime = now - then;
            then = now;
            tickBigSweep();

            //if (deltaTime > 0){//0.001) {
            if(do_sort){
                const swapped = applyBubbleSortStep();
                // if(
                //     noSwapStreak > 0 
                //     && !DID_COMPLETE_SORT_SINCE_RESET 
                //     && window.sortStepSize <= 2
                // ){
                //     DID_COMPLETE_SORT_SINCE_RESET = true;
                // }else{
                    if(
                        noSwapStreak > 0 // did we make it a full cycle with no swaps?
                        && !DID_COMPLETE_SORT_SINCE_RESET 
                        && window.sortStepSize > 2
                    ){
                        // let's start confirming by decreasing our sortStepSize
                        // reduce sortStepSize by factor of 2
                        window.sortStepSize = Math.max(2,parseInt(window.sortStepSize / 2));
                        console.warn('decreasing sortStepSize',window.sortStepSize);
                        if(window.sortStepSize <= 4){
                            // run our final sort pass
                            console.warn('final sort pass!')
                            DID_COMPLETE_SORT_SINCE_RESET = true;
                            finalSortPass();
                        }
                    }
                    if(
                        // if noSwapStreak reset, and we haven't completed the sort since the last reset
                        // and our current sortStepSize is less than our MAX_SORT_STEP_SIZE
                        // we increase the sortStepSize by factor of 2
                        noSwapStreak === 0 
                        && !DID_COMPLETE_SORT_SINCE_RESET 
                        && window.sortStepSize < window.MAX_SORT_STEP_SIZE
                    ){
                        // increase sortStepSize
                        window.sortStepSize = Math.min(window.MAX_SORT_STEP_SIZE,parseInt(window.sortStepSize * 2));
                        console.warn('increasing sortStepSize',window.sortStepSize,{
                            max: window.MAX_SORT_STEP_SIZE,
                        });
                    }
                //}
            }
            //}

            drawScene(gl, programInfo, outputSurfacePositionBuffer, deltaTime);

            requestAnimationFrame(render);

            if(window.capturing){
                try {
                    capturer.capture( canvas );
                } catch (error) {
                    console.log(error);
                }
            }
        }

        window.uScrollOffsetYSpeed = 0.05;
        window.uScrollOffsetXSpeed = -0.05;

        window.bigSweepActive = false, window.bigSweepInterval = 0;
        window.sweepFactor = 0.1;
        window.tickBigSweep = function() {
            if (window.bigSweepActive) {
                window.mouseX = (Math.sin(Date.now() * 0.001) + 1) * ((window.innerWidth / 2) * window.sweepFactor);
                window.mouseY = (Math.cos(Date.now() * 0.001) + 1) * ((window.innerHeight / 2) * window.sweepFactor);
            }
        }
        window.toggleBigSweep = function(){
            window.bigSweepActive = !window.bigSweepActive;
            console.warn("window.bigSweepActive",window.bigSweepActive);   
        }

        window.jiggleSwirl = false;
        window.swirlFreq = 1;
        window.swirlMax = 1;
        window.toggleJiggleSwirl = function(){
            window.jiggleSwirl = !window.jiggleSwirl;
            console.warn("window.jiggleSwirl",window.jiggleSwirl);

            clearInterval(window.mouseJiggler); 
            if(window.jiggleSwirl){
                window.mouseJiggler = setInterval(
                    ()=>{
                        window.mouseX = (Math.sin(Date.now()*window.swirlFreq*0.0015) * window.swirlMax*256)
                    },16)
            }
        }
        
        document.addEventListener('DOMContentLoaded', async () => {
            let imageElement = document.getElementById('image'); // Assuming there's an img element with id 'image'
            // create if not exist
            if(!imageElement){
                imageElement = document.createElement('img');
                imageElement.id = 'image';
                imageElement.style.display = 'none';
                document.body.appendChild(imageElement);
            }

            
        });
        function createImageBitmap(imageBlob){
            return new Promise((resolve,reject)=>{
                // let imageElement = document.getElementById('image'); // Assuming there's an img element with id 'image'
                // // create if not exist
                // if(!imageElement){
                //     imageElement = document.createElement('img');
                //     imageElement.id = 'image';
                //     imageElement.style.display = 'none';
                //     document.body.appendChild(imageElement);
                // }
                // imageElement.onload = function(e){
                //     // once we can read the image, we can forward it to our shader...
                //     resolve(imageElement);
                // }
                let _image = new Image();
                _image.onload = function(e){
                    // once we can read the image, we can forward it to our shader...
                    resolve(_image);
                }
                imageElement.src = URL.createObjectURL(imageBlob);
            });
        }
        async function onPasteAttempt(){
            try {
                    // Check if the Clipboard API is available
                    if (!navigator.clipboard) {
                        console.warn('Clipboard API not available.');
                        throw new Error('Clipboard API not available');
                    }

                    // Attempt to read from the clipboard
                    const clipboardItems = await navigator.clipboard.read();
                    console.log('Clipboard items retrieved:', clipboardItems);

                    let clipboardBag = {images:[]};

                    // Find text content in clipboard items
                    const textItem = clipboardItems.find(item => item.types.includes('text/plain'));
                    if (textItem) {
                        const textBlob = await textItem.getType('text/plain');
                        const text = await textBlob.text();
                        console.log('Pasted text content: ', text);
                        clipboardBag.text = text;
                    }

                    // Find HTML content in clipboard items
                    const htmlItem = clipboardItems.find(item => item.types.includes('text/html'));
                    if (htmlItem) {
                        const htmlBlob = await htmlItem.getType('text/html');
                        const html = await htmlBlob.text();
                        console.log('Pasted HTML content: ', html);
                        clipboardBag.html = html;
                    }
                    // Note: imageBlob is an instance of Blob
                    // to get pixel data OUT of the blob and INTO 3D space, we need to load it as a texture
                    // to do THAT (we need to assume it could be a _local_ file so we _can not_ use the img.src shortcut,)
                    // we need to do the slow, full conversion of a Blob to a base64 encoded string
                    // then we can use that base64 encoded string to load the image as a texture
                    


                    // Find any "image" items:
                    const imageItems = clipboardItems.filter(item => item.types.includes('image/png'));
                    // Alert if there's multiple, we only support one for now
                    if (imageItems.length > 1) {
                        alert('Multiple images found. Using the last image.');
                    }
                    for (const imageItem of imageItems) {
                        const imageBlob = await imageItem.getType('image/png');
                        //console.log('Pasted image: ', image);
                        clipboardBag.imageBlob = imageBlob;

                        //loadImageBlobAsTexture(imageBlob);
                        
                        let b64 = await imageBlobToBase64(imageBlob);
                        //console.log('Pasted image: ', b64);

                        await loadBase64AsTexture(b64);
                        clipboardBag.images.push(b64);
                    }

                    hideIntroText()

                    // Process clipboardBag as needed
                    console.warn({clipboardBag});

                } catch (error) {
                    console.error('Error accessing clipboard:', error);
                    // Handle error appropriately
                }
        }
        function hideIntroText(){
            canvas.classList.add('unblur');
            let match = document.getElementsByClassName('drop-here-text');
            if (match.length > 0) {
                Array.from(match).forEach((el) => {
                    el.classList.add('fadeout');
                });
            }
        }
        function showIntroText(skipBlur=false){
            if(!skipBlur){
                canvas.classList.remove('unblur');
            }
            let match = document.getElementsByClassName('drop-here-text');
            if (match.length > 0) {
                Array.from(match).forEach((el) => {
                    el.style.display = 'block';
                });
            }
        }
        document.addEventListener('keydown',async(e)=>{
            // if command v on mac,
            // or control v on other,
            // paste image from clipboard
            if ( 
                (e.keyCode === 22 || e.keyCode === 86)
                && (e.metaKey || e.ctrlKey)
            ){
                await onPasteAttempt();
            }
        },false)

        document.addEventListener('touchmove',async(e)=>{
            mouseX = e.touches[0].clientX;
            mouseY = e.touches[0].clientY;
        })

        // Mobile double-tap detection
        let doubleTapDetected = false;
        let doubleTapTimeout = null;
        const doubleTapDelay = 300;

        // uniform "double-tap"/double-click detection

        function checkDoubleTapDetected(){
            if (doubleTapDetected) {
                // Reset
                doubleTapDetected = false;
                clearTimeout(doubleTapTimeout);
                doubleTapTimeout = null;
                
                showIntroText();
                
                // Actions to perform on double tap
                showIntroText(true); // Assuming skipBlur is a parameter of showIntroText
                loadImageAsTexture("./res/360_F_202297164_NSSIqkr7QKi5Ltjrizwh9XGzH0MNANRN.jpg");
            } else {
                doubleTapDetected = true;
                doubleTapTimeout = setTimeout(() => {
                    // Actions to perform if not a double tap
                    // Currently, it's set to perform the same actions, 
                    // but you can change this to suit your needs.

                    // Reset double tap detection
                    doubleTapDetected = false;
                    doubleTapTimeout = null;
                }, doubleTapDelay);
            }
        }

        document.addEventListener('touchend', (e) => {
            checkDoubleTapDetected();
        }, false);
        var num_modes = 5;
        document.addEventListener('click', (e)=>{
            MODE = (MODE + 1) % num_modes;
            console.log("MODE",MODE);

            checkDoubleTapDetected();

            if(!window.do_sort){
                window.do_sort = true;
                console.log("do_sort",window.do_sort);
            }
        });
        window.mouseX = window.mouseY = 0;
        document.addEventListener('mousemove', (e)=>{
            window.mouseX = e.clientX;
            window.mouseY = e.clientY;
        });

        let uniforms = []
        function maybeSetUniforms(gl){
            if(uniforms.length > 0){
                return;
            }
            uniforms = [
                //uReflectionX
                { t: "uniform1f", k: "uReflectionX", getter: _=>window.uReflectionX},
                { t: "uniform1f", k: "uReflectionY", getter: _=>window.uReflectionY},
                { t: "uniform1i", k: "uSortOffset", getter: _=>parseInt(sortOffset/numPixels)},
                { t: "uniform1i", k: "uSortStepSize", getter: _=>parseInt(sortStepSize)},
                { t: "uniform2f", k: "uResolution", getter: _=>[
                    Math.floor(canvas.width/pixel_density), 
                    Math.floor(canvas.height/pixel_density)
                ]},
                { t: "uniform1f", k: "uTime", getter: _=>performance.now() / 1000},
                { t: "uniform1i", k: "uPxDensity", getter: _=>pixel_density},
                { t: "uniform1i", k: "uMode", getter: _=>MODE},
                
                // 
                { t: "uniform1i", k: "uOffsetTexture", getter: _=>0},
                { t: "uniform1i", k: "uBaseTexture", getter: _=>1},
                { t: "uniform1i", k: "uSelectedImageTexture", getter: _=>2},
                { t: "uniform1i", k: "uOriginalPixelDataTexture", getter: _=>3},
                { t: "uniform1i", k: "uUpdatedPixelDataTexture", getter: _=>4},
                { t: "uniform1i", k: "uLerpedColorTexture", getter: _=>5},

                { t: "uniform1f", k: "uScrollOffsetYSpeed", getter: _=>window.uScrollOffsetYSpeed},
                { t: "uniform1f", k: "uScrollOffsetXSpeed", getter: _=>window.uScrollOffsetXSpeed},

                // gl.uniform1f(UL.uSwirlTurns, uSwirlTurns);
                { t: "uniform1f", k: "uSwirlTurns", getter: _=>uSwirlTurns},
                // gl.uniform1f(UL.uSwirlAmp, uSwirlAmp);
                { t: "uniform1f", k: "uSwirlAmp", getter: _=>uSwirlAmp},
            ]
        }

        // draw scene
        function drawScene(gl, programInfo, deltaTime) {
            maybeSetUniforms(gl);

            // draw a red square and return
            gl.clearColor(1.0, 0.0, 1.0, 1.0);
            // return;

            // gl.clearColor(0.0, 0.0, 0.0, 1.0);  // Clear to black, fully opaque
            gl.clearDepth(1.0);                 // Clear everything
            gl.enable(gl.DEPTH_TEST);           // Enable depth testing
            gl.depthFunc(gl.LEQUAL);            // Near things obscure far things

            // Clear the canvas
            gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

            

            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, offsetTexture);

            // Only use R and G channels, force A channel to 1
            pixelData = pixelData.map((value, index) => {
                // ignore green channel
                if (index === 2) {
                    return 0;
                }
                // full alpha
                if (index === 3) {
                    return 255;
                }
                // clamp to 0-255
                return Math.max(0, Math.min(255, value));
            });

            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixelData);

            if(typeof window.DID_BIND_BASE_SINCE_RESIZE == "undefined"||window.DID_BIND_BASE_SINCE_RESIZE === false){
                window.DID_BIND_BASE_SINCE_RESIZE = true;
                gl.activeTexture(gl.TEXTURE1);
                gl.bindTexture(gl.TEXTURE_2D, baseTexture);

                // clone data into originalPixelDataTexture
                gl.activeTexture(gl.TEXTURE3);
                gl.bindTexture(gl.TEXTURE_2D, originalPixelDataTexture);
            }

            // Adjusting the origin to be the middle of the window
            let midX = window.innerWidth / 2;
            let midY = window.innerHeight / 2;

            // Adjust mouseX and mouseY to be relative to the middle of the window
            let adjustedMouseX = mouseX - midX;
            let adjustedMouseY = mouseY - midY;

            // Mapping swirl turns to adjustedMouseX
            // -midX (-1) - midX (1) => 1 - 4
            uSwirlTurns = 1 + (adjustedMouseX / midX) * 3;

            // Mapping swirl amplitude to adjustedMouseY
            // -midY (-1) - midY (1) => 0.001 - 3
            uSwirlAmp = 0.001 + (adjustedMouseY / midY) * 3;            

            // Use our program when drawing
            gl.useProgram(programInfo.program);

            // Update the shader uniforms
            const UL = programInfo.uniformLocations;
            uniforms.forEach(({t,k,getter})=>{
                if(typeof gl[t] !== 'function'){
                    throw new Error("gl[t] is not a function",{
                        t,k,getter,
                        glt: gl[t],
                    });
                }
                // console.warn('uniforms.forEach',{t,k,getter})
                // console.warn({key:k,thing:typeof UL[k]});
                if(typeof getter !== 'function'){
                    throw new Error("getter is not a function",{
                        t,k,getter,
                        glt: gl[t],
                        ULk: UL[k],
                    });
                }
                let extras = [];
                if(t === 'uniform2f'){
                    extras = getter();
                }else if(t === 'uniform1f' || t === 'uniform1i'){
                    extras = [getter()];
                };
                gl[t](UL[k], ...extras);
            })

            

            {
                const offset = 0;
                const vertexCount = 6;
                gl.drawArrays(gl.TRIANGLES, offset, vertexCount);
            }
        }

        function imageBlobToBase64(imageBlob){
            return new Promise((resolve,reject)=>{
                let reader = new FileReader();
                reader.onload = function(e){
                    resolve(e.target.result);
                }
                reader.readAsDataURL(imageBlob);
            });
        }

        // async function loadImageBlobAsTexture(imageBlob){
        //     imageTex = gl.createTexture();
        //     gl.bindTexture(gl.TEXTURE_2D, imageTex);
            
        //     // Set the parameters so we can render any size image.
        //     gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        //     gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

        //     // when texture area is small, bilinear filter the closest mipmap
        //     gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

        //     // when texture area is large, bilinear filter the first mipmap
        //     gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

        //     // preload the texture will all green pixels
        //     gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE,new Uint8Array([0, 255, 0, 255]));

        //     // Upload the image into the texture.
        //     const level = 0;
        //     const internalFormat = gl.RGBA;
        //     const srcFormat = gl.RGBA;
        //     const srcType = gl.UNSIGNED_BYTE;

        //     const image = new Image();
        //     image.onerror = function(e) {
        //         console.error("Error loading image",e);
        //     };
        //     image.onabort = function(e) {
        //         console.error("Error loading image",e);
        //     };
        //     image.onload = function(e) {
        //         gl.bindTexture(gl.TEXTURE_2D, imageTex);
        //         gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, srcFormat, srcType, image);

        //         // load into baseTexture
        //         gl.bindTexture(gl.TEXTURE_2D, baseTexture);
        //         // base texture might have different dimensions, so we need to scale to FILL
        //         let croppedToFillPixels = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
        //         let croppedToFillPixelsIndex = 0;
        //         // Calculate offsets
        //         let offsetX = Math.max(0, (image.width - fixedPixelsX) / 2);
        //         let offsetY = Math.max(0, (image.height - fixedPixelsY) / 2);
        //     };
        //     console.warn('imageBlob',{
        //         imageBlob,
        //         blobObjUrl: URL.createObjectURL(imageBlob),
        //         blobAsImageBase64: await imageBlobToBase64(imageBlob),
        //     })
        //     image.src = URL.createObjectURL(imageBlob);
        //     let el = document.body.appendChild(image);
        // }

        let pastedTexture;
        function loadBase64AsTexture(b64){
            // assume string input

            if(!b64.startsWith('data:image/png;base64,')){
                throw new Error("b64 is not a valid base64 encoded image",b64);
                //b64 = 'data:image/png;base64,' + b64;
            }

            // Create and load the image
            const image = new Image();
            image.onerror = function(e) { console.error("Error loading image", e); };
            image.onabort = function(e) { console.error("Error loading image", e); };
            image.onload = function() {
                console.warn('image loaded',{image});
                handleImageLoad(image);
            };
            image.src = b64;
            let el = document.body.appendChild(image);
            console.warn('image.src',{el,src:image.src});
        }

        let imageTex;
        function loadImageAsTexture(imageSource) {
            resetOffsetTexture();
            imageTex = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, imageTex);

            // Set the parameters so we can render any size image.
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

            // Preload the texture with all green pixels
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array([0, 255, 0, 255]));

            // Create and load the image
            const image = new Image();
            image.onerror = function(e) { console.error("Error loading image", e); };
            image.onabort = function(e) { console.error("Error loading image", e); };
            image.onload = function() {
                handleImageLoad(image);
            };
            image.src = imageSource;
            let el = document.body.appendChild(image);
        }
        /*
        function loadImageAsTexture(url){
            // ./res/Screen-interface-design-Bill-Atkinson-Susan-Kare-1983.webp
            imageTex = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, imageTex);
            
            // Set the parameters so we can render any size image.
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

            // when texture area is small, bilinear filter the closest mipmap
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

            // when texture area is large, bilinear filter the first mipmap
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

            // preload the texture will all green pixels
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE,new Uint8Array([0, 255, 0, 255]));

            // Upload the image into the texture.
            const level = 0;
            const internalFormat = gl.RGBA;
            const srcFormat = gl.RGBA;
            const srcType = gl.UNSIGNED_BYTE;

            const image = new Image();
            image.onerror = function(e) {
                console.error("Error loading image",e);
            };
            image.onabort = function(e) {
                console.error("Error loading image",e);
            };
            image.onload = function(e) {
                gl.bindTexture(gl.TEXTURE_2D, imageTex);
                gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, srcFormat, srcType, image);

                // load into baseTexture
                gl.bindTexture(gl.TEXTURE_2D, baseTexture);
                // base texture might have different dimensions, so we need to scale to FILL
                let croppedToFillPixels = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
                let croppedToFillPixelsIndex = 0;
                // Calculate offsets
                let offsetX = Math.max(0, (image.width - fixedPixelsX) / 2);
                let offsetY = Math.max(0, (image.height - fixedPixelsY) / 2);
                
                // let tempImagePixelData = new Uint8Array(image.width * image.height * bytesPerPixel);
                // for(let i = 0; i < tempImagePixelData.length; i++){
                //     tempImagePixelData[i] = image.data[i];
                // }


                console.warn("image.data.length",image?.data?.length,{image})
                for (let y = 0; y < fixedPixelsY; y++) {
                    for (let x = 0; x < fixedPixelsX; x++) {
                        // Adjust index to center the image
                        let originalX = x + offsetX;
                        let originalY = y + offsetY;
                        
                        let index;
                        if (originalX < image.width && originalY < image.height) {
                            // Pixel is within the bounds of the original image
                            index = (originalY * image.width + originalX) * 4;
                        } else {
                            // Pixel is outside the bounds, use a default value
                            index = -1;
                        }

                        if(!image.data) console.error("image.data is undefined");
                        if(!image.data.length) console.error("image.data.length is ",image.data.length);
                        

                        if (index >= 0) {
                            // Copy pixel data
                            croppedToFillPixels[croppedToFillPixelsIndex++] = image.data[index];
                            croppedToFillPixels[croppedToFillPixelsIndex++] = image.data[index + 1];
                            croppedToFillPixels[croppedToFillPixelsIndex++] = image.data[index + 2];
                            croppedToFillPixels[croppedToFillPixelsIndex++] = image.data[index + 3];
                        } else {
                            // Default pixel value (e.g., transparent)
                            croppedToFillPixels[croppedToFillPixelsIndex++] = 0;
                            croppedToFillPixels[croppedToFillPixelsIndex++] = 0;
                            croppedToFillPixels[croppedToFillPixelsIndex++] = 0;
                            croppedToFillPixels[croppedToFillPixelsIndex++] = 0;
                        }
                    }
                }
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, croppedToFillPixels);
            };
            image.src = url;
        }
        */

        function handleImageLoad(image) {
            console.warn('handleImageLoad',{image})
            gl.bindTexture(gl.TEXTURE_2D, imageTex);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);

            handleImageLoadForBaseTex(image);

            DID_COMPLETE_SORT_SINCE_RESET = false;
        }

        function handleImageLoadForBaseTex(image) {
            console.warn('handleImageLoadForBaseTex',{image})
            // ARE WE SURE the image loaded?
            if(image.width === 0 || image.height === 0){
                throw new Error("Image did not load");
            }
            console.warn('imgdata at this time:',{
                w:image.width,
                h:image.height,
                imgW:image.width,
                imgH:image.height,
                blobURL: image.src,
            })

            baseTexWidth = fixedPixelsX;
            baseTexHeight = fixedPixelsY;
            // Calculate scale and translation
            let scaleX = baseTexWidth / image.width;
            let scaleY = baseTexHeight / image.height;
            let scale = Math.min(scaleX, scaleY); // Choose the smaller scale to fit the image within baseTex
            let translateX = (baseTexWidth - image.width * scale) / 2;
            let translateY = (baseTexHeight - image.height * scale) / 2;

            // Draw the image onto an off-screen canvas to get its pixel data
            let offscreenCanvas = document.createElement('canvas');
            offscreenCanvas.width = image.width;
            offscreenCanvas.height = image.height;

            window.debug_offscreenCanvas = offscreenCanvas;

            console.warn('offscreenCanvas',{
                w:offscreenCanvas.width,
                h:offscreenCanvas.height,
                imgW:image.width,
                imgH:image.height,
            });

            let ctx = offscreenCanvas.getContext('2d');
            ctx.drawImage(image, 0, 0);
            let imageData = ctx.getImageData(0, 0, image.width, image.height);

            // check if image data is all 0s...
            let allZero = true;
            for(let i = 0; i < imageData.data.length; i++){
                if(imageData.data[i] !== 0){
                    allZero = false;
                    console.warn('non-zero pixel data @ i:v',i,imageData.data[i]);
                    break;
                }
            }
            if(allZero){
                throw new Error("Image data is all 0s",{
                    imageData,
                    image,
                });
            }
            let countNonzero = 0;
            // jump in steps of four, ignore rgb if alpha is lower than 1
            for(let i = 0; i < imageData.data.length; i+=4){
                if(imageData.data[i+3] > 0){
                    // only count if at least 1 component is non-zero
                    if(imageData.data[i] > 0 || imageData.data[i+1] > 0 || imageData.data[i+2] > 0){
                        countNonzero++;
                    }
                }
            }
            console.warn('% nonzero',countNonzero/(imageData.data.length/4));

            // Create a new pixel array for baseTex
            let baseTexPixels = new Uint8Array(baseTexWidth * baseTexHeight * 4); // Assuming RGBA

            // Copy pixels with scaling and translation
            for (let y = 0; y < baseTexHeight; y++) {
                for (let x = 0; x < baseTexWidth; x++) {
                    let sourceX = Math.floor((x - translateX) / scale);
                    let sourceY = Math.floor((y - translateY) / scale);

                    // invert y axis
                    sourceY = image.height - sourceY;

                    let baseIndex = (y * baseTexWidth + x) * 4;
                    if (sourceX >= 0 && sourceX < image.width && sourceY >= 0 && sourceY < image.height) {
                        let sourceIndex = (sourceY * image.width + sourceX) * 4;
                        baseTexPixels[baseIndex] = imageData.data[sourceIndex];       // R
                        baseTexPixels[baseIndex + 1] = imageData.data[sourceIndex + 1]; // G
                        baseTexPixels[baseIndex + 2] = imageData.data[sourceIndex + 2]; // B
                        baseTexPixels[baseIndex + 3] = imageData.data[sourceIndex + 3]; // A
                    } else {
                        // Fill with a default color or transparent
                        baseTexPixels[baseIndex] = 0;     // R
                        baseTexPixels[baseIndex + 1] = 0; // G
                        baseTexPixels[baseIndex + 2] = 0; // B
                        baseTexPixels[baseIndex + 3] = 0; // A
                    }
                }
            }

            //console.warn(baseTexPixels.length,baseTexPixels)

            // overwrite pixelData array with baseTexPixels
            pixelData = baseTexPixels;
            // clone
            originalPixelData = baseTexPixels.slice(0);

            // Bind to baseTex and update its texture
            gl.bindTexture(gl.TEXTURE_2D, baseTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, baseTexWidth, baseTexHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, baseTexPixels);

            gl.bindTexture(gl.TEXTURE_2D, originalPixelDataTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, baseTexWidth, baseTexHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, originalPixelData);

            //console.warn('loaded number of pixels',baseTexPixels.length/4, baseTexPixels);
            
        }

        document.getElementById('imageLoader').addEventListener('change', handleImage2, false);

        async function handleImage2(e) {
            hideIntroText();
            hideVideo();
            console.warn("handleImage2",e);
            var reader = new FileReader();
            reader.onload = function(event) {
                if(event.target.readyState != FileReader.DONE) return;
                var img = new Image();
                console.warn("handleImage2>reader.onload",event);
                img.onload = function() {
                    console.warn('handleImage2>img',img);
                    //selectedImageTexture = gl.createTexture();
                    gl.useProgram(programInfo.program);
                    //gl.bindTexture(gl.TEXTURE_2D, selectedImageTexture);
                    gl.bindTexture(gl.TEXTURE_2D, baseTexture);
                    gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
                    gl.bindTexture(gl.TEXTURE_2D, null);
                    if(gl.getError() != gl.NO_ERROR) {
                        console.error("handleImage2>img>gl error",gl.getError());
                        debugger;
                    }
                }
                img.src = event.target.result;
            }
            reader.readAsDataURL(e.target.files[0]);     
        }


        function onImageDrop(event) {
            // Handle image drop, load the image into baseTexture
            event.preventDefault();

            hideIntroText();
            try {
                const file = event.dataTransfer.files[0];
                const reader = new FileReader();
                reader.onload = function(event) {
                    loadImageAsTexture(event.target.result); // Use loadImageAsTexture function
                    do_sort = true
                    MODE = 1;
                };
                reader.readAsDataURL(file);
            } catch (e) {
                console.error('Error loading dropped image', e);
            }
        }

        
        document.addEventListener("DOMContentLoaded", onReady);

    </script>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GYK2ZMX0M9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GYK2ZMX0M9');
</script>
</body>
</html>
