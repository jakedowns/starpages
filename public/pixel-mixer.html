<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <!-- 
        https://jakedowns.github.io/starpages/webgl2.html
        TODO:
        - bitonic sort
    
        // finish back merging "video texture" / three.js bindings
    
        // finish triple-buffering
        - lerping between colors using an intermediary accumulator texture which we display
            // backed by our current Original, and Target textures

        Textures List:
            
            1. originalPixelDataTexture (an untouched copy of the original image)
            2. targetPixelDataTexture
            3. lerpedColorTexture 
            4. offsetTexture

            5. inputTextureA (renaming to inputTextureA)
            6. inputTextureB (renaming to inputTextureB)

        Materials List:
            
            1. (unused) mandleBulbMaterial: ShaderMaterial (the image / video / gif uploaded by the user)
                - iChannel0: Texture
                - iResolution: Vector3
                - iMouse: Vector4
                - iMouseRaw: Vector4
                - iMouseWheel: Vector4
                - iTime: float
        2. 
    -->
    <script>
        window.capturerSpeedReduction = 0.5;
    </script>
    <title>🎨 pixel mixer 🧪</title>
    
    <meta property="og:title" content="🎨 pixel mixer 🧪" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jakedowns.github.io/starpages/public/pixel-mixer.html" />
    <meta property="og:image" content="https://jakedowns.github.io/starpages/res/pixel-mixer.png" />

    <meta property="og:description" content="Pixel Mixer is a web-based tool for creating unique visual effects." />
    <meta property="og:determiner" content="the" />
    <meta property="og:locale" content="en_US" />
    <!-- <meta property="og:locale:alternate" content="fr_FR" /> -->
    <!-- <meta property="og:locale:alternate" content="es_ES" /> -->
    <meta property="og:site_name" content="Pixel Mixer" />
    <script type="importmap">
        {
          "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "three/examples/": "https://jakedowns.github.io/starpages/public/three/examples/"
          }
        }
    </script>
    <!-- <script src="/public/three/build/three-webgpu.module.js" type="module"></script> -->
    <!-- <script src="/public/three/examples/jsm/renderers/webgpu/WebGPURenderer.js" type="module"></script> -->
    
    <script src="https://jakedowns.github.io/starpages/res/CCapture.all.min.js"></script>
    <link href="https://unpkg.com/tailwindcss@^2.0.2/dist/tailwind.min.css" rel="stylesheet">
    <script src="https://unpkg.com/lil-gui@0.19.1/dist/lil-gui.umd.js"></script>
    
    <style>
        html, body { margin: 0; padding: 0; overflow: hidden;  background-color: #000; }
        canvas#canvas {
            position: absolute;
            top: 0; left: 0; right: 0; bottom: 0;
    
            
            width: 100vw; 
            min-Width: 100vw; 
            max-width: 100vw;
            height: 100vh;
            min-height: 100vh;
            max-height: 100vh; 

            /* filter: blur(100px);  */
            opacity: 1;
            transition: filter 0.5s ease-in-out, opacity 0.5s ease-in-out; 
            will-change: filter; 
        }
        canvas.unblur { filter: blur(0px); opacity: 1; }
        canvas.undarken { opacity: 0.8; }
        .drop-here-text {
            pointer-events: none;
            position: absolute;
            left: 0; right: 0; top: 0; bottom: 0;
            z-index: 4000;
            font-size: 43px;
            font-weight: bold;
            text-align: center;
            color: white;
            font-family: sans-serif;
            text-shadow: 4px 4px 5px black, 5px 5px 5px blue;
            -webkit-text-strokes: 1px black;
            top: 50%;
            transform: translateY(-50%);
            transition: all 1s ease-in-out;
        }
        .drop-here-text.fadeout {
            opacity: 0;
            pointer-events: none;
        }
        .drop-here-text span {
            display: block;
            font-size: 25px;
        }
        .drop-here-text.fadeout span {
            pointer-events: none;
        }
        .drop-here-text .hint {
            font-size: 15px;
        }
        .intro-card {
            top: 50%;
            position: absolute;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1000;
            display: block;
            width: 100%;
            max-width: 100vw;
            padding: 20px;
            box-sizing: border-box;
            opacity: 1;
        }
        .intro-card.fade-out {
            opacity: 0;
            pointer-events: none;
        }
        .intro-card iframe {
            height: auto;
            width: 100%;
            min-width: 100px;
            max-width: 100%;
        }
        p {
            color: white;
            font-size: 12px;
            font-family: serif;
        }
        h1 {
            font-family: sans-serif;
        }
        .intro-underlay {
            background-color: rgba(.1,0,.1,.8);
            backdrop-filter: blur(10px);
            position: absolute;
            z-index: 999;
            top: 0; left: 0; right: 0; bottom: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .intro-underlay.fade-out {
            opacity: 0;
            pointer-events: none;
        }
        .hide-intro-button {
            text-align: center;
            width: auto;
            margin: 0 auto;
            position: relative;
            display: block;
            border-radius: 100px;
            border: 2px solid black;
            padding: 10px 20px;
            box-sizing: border-box;
            font-size: 20px;
            color: white;
            cursor: pointer;
            transition: all 1s ease-in-out;
            background-color: #663dff;
            font-family: sans-serif;
            text-shadow: 1px 1px 3px rgba(0,0,0,0.8);
            background-size: 200% auto;
            background-image: linear-gradient(90deg, #cc4499, #aa00ff, #663dff, #aa00ff, #cc4499);
            transition: all 1s ease-in-out;
            /* Apply the animation */
            animation: gradient-animation 2s linear infinite;
        }

        /* here we use a rounded rectangle + a linear gradient to emulate gloss via psuedo element */
        .hide-intro-button .btn-inner::after {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            width: 100%;
            height: 100%;
            border-radius: 100px;
            background-color: rgba(255,255,255,0.1);
            z-index: 1;
            backdrop-filter: blur(50px);
        }


        
        .hide-intro-button .btn-text {
            position: relative;
            font-size: 18px;
            z-index: 2;
            color: white;
            text-shadow:  1px 1px 10px rgba(255,255,255,1); /* 1px 1px 1px rgba(0,0,0,0.8), */
            cursor: pointer;
        }

        /*
            1. we reflect the gradient over the Y axis
            2. we animate the gradient over time from left to right infinitely
            3. [#cc4499, #aa00ff, #663dff, #aa00ff, #cc4499]
            4. we use a linear gradient to emulate gloss
            5. we stretch it to 2x the width of the button
        */
        @keyframes gradient-animation {
            0% { background-position: 0% 50%; }
            99.99% { background-position: -200% 50%; }
            100% { background-position: 0% 50%; }
        }

        #controls {
            position: absolute;
            right: 0;
            top: 0;
            width: 100px;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: space-evenly;
            align-items: stretch;
        }
        video {
            position: absolute;
            left: 0;
            opacity: 0.1;
            transition: all 1s ease-in-out;
            bottom: 100px;
            width: 100px;
        }
        video:hover {
            opacity: 1;
            width: 300px;
        }
        #record-video-button {
            position: absolute;
            bottom: 10px;
            right: 10px;
            width: 100px;
            z-index: 1000;
        }

        /* final z-indexes */
        .intro-card { z-index: 1002; position: absolute; }
        .intro-underlay { z-index: 1001; }
        #controls { z-index: 1000; }
        video { z-index: 1000; }
        canvas { z-index: 999; }

        .view-source-link {
            position: absolute; 
            top: 0; 
            right: 0; 
            z-index: 9999; 
            font-size: 10px; 
            font-family: sans-serif; 
            color: white; 
            text-decoration: none; 
            padding: 5px; 
            background-color: black; 
            opacity: 0.5;
            transition: all 1s ease-in-out;
            &:hover {
                opacity: 1;
            }
        }
    </style>
</head>
<body>
    <!-- todo: gif support -->
    <!-- view source on github -->
    <a href="https://github.com/jakedowns/starpages/blob/main/webgl2.html" 
    class="view-source-link" target="_blank">view source on GitHub</a>

    <!-- buy me a coffee; ko-fi link -->
    <a href="https://ko-fi.com/jakedowns" target="_blank" style="position: absolute; top: 0; left: 0; z-index: 1003; font-size: 10px; font-family: sans-serif; color: white; text-decoration: none; padding: 5px; background-color: black; opacity: 0.5;">☕🥰 Buy me a coffee</a>

    <div id="controls"> 
        <input type="file" accept="image/*,video/*,image/svg+xml" id="fileupload" />
        <progress id="progress" value="0" max="100"></progress>
        <button onclick="window.startCapture()">record video</button>
    </div>

    <div class="intro-card transition-opacity fade-out">
        <h1>Pixel Mixer Demo</h1>
        <p>v24.01.01.01 - Major Release 001</p>
        <p>Shout out to acerola on youtube for his original "I tried sorting pixels" video which inspired me to dig back into this</p>
        <p>Drop images and video on this webpage to have them mixed and blended in unique ways</p>
        <p>⚠️ Flashing Light Warning ⚠️ <br/>this app produces rapidly flashing light patterns. I'm working on a "safe" comfort mode - but for now, do not use it if you are photo-sensitive. 🙇🏻‍♂️🙏🏻</p>
        <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/NGA-Sc-2XTg?si=YxW01ggV4KRXI-U4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
        
        <button class="hide-intro-button">
            <span class="btn-inner">
                <span  class="btn-text" onclick="window.hideWelcome()">Click to Continue ➡️</span>
            </span>
        </button>
    </div>

    <div class="intro-underlay fade-out" onclick="window.hideWelcome()"></div>

    <div class="drop-here-text fadeout">pixel mixer<span>drop an image here<br/>or<br/>tap here to select an image <span class="hint">(local only, doesn't get uploaded anywhere)</span></span></div>
    
    <canvas id="canvas" class="undarken"></canvas>
    <script type="module">
        import * as THREE from 'three';
        import { VRButton } from 'three/examples/jsm/webxr/VRButton.js';
        //import { WebGPURenderer } from 'three/addons/renderers/webgpu/WebGPURenderer.js';
        import { EffectComposer } from 'three/examples/jsm/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/examples/jsm/postprocessing/RenderPass.js';
        import { ShaderPass } from 'three/examples/jsm/postprocessing/ShaderPass.js';
        import { OutputPass } from 'three/addons/postprocessing/OutputPass.js';
        import { UnrealBloomPass } from 'three/examples/jsm/postprocessing/UnrealBloomPass.js';

        import { GammaCorrectionShader } from 'three/examples/jsm/shaders/GammaCorrectionShader.js';

        // import { SSAOPass } from 'three/addons/postprocessing/SSAOPass.js';
        // import { BloomEffect } from 'three/examples/jsm/effects/BloomEffect.js';
        // import { VignetteEffect } from 'three/examples/jsm/effects/VignetteEffect.js';
        
        import { VignetteShader } from 'three/examples/jsm/shaders/VignetteShader.js';
        let canvas;
        

        const dpr = 1; // window.devicePixelRatio;
        const presentationFormat = navigator?.gpu?.getPreferredCanvasFormat();
        window.pixelWidth = window.innerWidth;
        window.pixelHeight = window.innerHeight;
        window.canvas;
        window.uReflectionY = 0.5; // 0.5 = no reflection, 0 = full reflection, 1 = no reflection
        window.reverseSort = true;
        window.capturer = null;
        window.capturing = false;
        window.targetRecordingFPS = 29.97; //120;
        window.targetRecordingDurationSeconds = 30;
        Object.defineProperty(window, 'maxFrames', {
            get: function() { return this.targetRecordingFPS * 10; }
        });

        // define fixedTime
        // a wall time we can hold to pause the shader
        Object.defineProperty(window, 'fixedTime', {
            get() { 
                return window.targetVideoPlaybackRate >= 0.1 ? null : this._fixedTime;
             },
            set(value) {
                this._fixedTime = value;
            }
        });

        window.videoIsPlaying = false;
        // used to distinguish element's playback state from our virtual playback state(sub-0.1x playback rate)
        window.videoIsVirtuallyPlaying = false; 
        // window.recordingStartedAt = 0;
        window.subframePlaybackCurrentFrame = 0;
        window.currentVideoTime = null;
        window.inputTextureA = null;
        window.inputTextureB = null;

        window.shaderTimeIsPaused = false;
        window.theVideoplayerElement = null;
        let _targetVideoPlaybackRate = 0.01;
        let _targetVideoPlaybackRateClamped = 0.1;
        Object.defineProperty(window, 'targetVideoPlaybackRate', {
            get: function() {
                return _targetVideoPlaybackRate;
            },
            set: function(value) {
                _targetVideoPlaybackRate = value;
                _targetVideoPlaybackRateClamped = parseFloat(Math.min(Math.max(value, 0.1), 1.0).toFixed(1));
                if (window.theVideoplayerElement) {
                    window.theVideoplayerElement.playbackRate = _targetVideoPlaybackRateClamped;
                }else{
                    console.warn('no video element to set playback rate on')
                }
            }
        });

        // was: fsSource
        /*
            // bare bones debug
            // make sure we set, otherwise safari won't work
            //     fsSource = `
            // precision mediump float;
            // void main() {
            //     gl_FragColor = vec4(1.0,0.0,0.0,1.0);
            // }
            // `
        */
        //window.fragmentShaderSource = null;
        
        window.selectedImageTexture;
        window.shaderMaterial;

        window.oninputTextureARefresh = function(){
            // 1. reset Offset texture
            // 2. clone base -> target (refresh)
            // 3. clone base -> accumulator (refresh)
            // 4. clone base -> lerped (refresh)?
        }

        // window.switchToImageTexture
        
        // may have changed pixel resolution
        // TODO: maybe make sure we set three to just fill/crop whatever we're trying to display to fit our existing pixel resolution
        window.reinitTexturesOnNewInput = function(){
            // 1. reset Offset texture
            // 2. clone base -> target (refresh)
            // 3. clone base -> accumulator (refresh)
            // 4. clone base -> lerped (refresh)?
        }

        let handling_slow_motion_advance = false;

        function maybeAdvanceVideoOneFrame() {
            if(!window.targetVideoPlaybackRate >= 0.1){
                handling_slow_motion_advance = false;
                return;
            }
            if(handling_slow_motion_advance){
                return;
            }
            //theVideoplayerElement.pause();
            handling_slow_motion_advance = false;

            let frameDuration = 1 / window.targetRecordingFPS; //framerate;
            let desiredSpeed = window.targetVideoPlaybackRate;// 0.05; // Replace with your desired speed
            let playDuration = frameDuration / desiredSpeed;

            let do_advance_virtual_frame_this_literal_frame = window.subframePlaybackCurrentFrame % Math.floor(1 / desiredSpeed) == 0;
            if(!do_advance_virtual_frame_this_literal_frame){
                return;
            }
            subframePlaybackCurrentFrame++;
            // currentTime is also not precise enough for sub-frame playback
            // we will hit play then pause in a short manner
            // the min time beyond the point where a "play was cancelled by pause" is ??ms ?
            //theVideoplayerElement.currentTime += frameDuration;
            window.playSlowMotion = function() {
                // console.warn("onPlaySlowMotion",{
                //     frameDuration,
                //     targetFPS: window.targetRecordingFPS,
                //     desiredSpeed,
                //     playDuration,
                // });
                setTimeout(() => {
                    handling_slow_motion_advance = true;
                    theVideoplayerElement.play();
                }, 32);
                // onseek we call BACK to this function to pause and continue slow motion
            }

            theVideoplayerElement.addEventListener('seeked', () => {
                if (handling_slow_motion_advance) {
                    playSlowMotion();
                }
            });

            // theVideoplayerElement.addEventListener('pause', () => {
            //     if (handling_slow_motion_advance && theVideoplayerElement.currentTime < theVideoplayerElement.duration) {
            //         theVideoplayerElement.currentTime += frameDuration;
            //     }
            // });

            
        }

        let minRadius = 10.0;
        let maxRadius = 100.0;
        let minX = 0.0;
        let maxX = 100.0;
        let minY = 0.0;
        let maxY = 100.0;

        document.addEventListener('wheel', (e) => {
            // Assuming minRadius and maxRadius are your minimum and maximum values for radius
            settings.radius = Math.max(minRadius, Math.min(maxRadius, settings.radius + e.deltaY * 0.01));

            // Assuming minX, maxX, minY, maxY are your minimum and maximum values for vec2MouseWheelRaw.x and vec2MouseWheelRaw.y
            vec2MouseWheelRaw.set(
                Math.max(minX, Math.min(maxX, vec2MouseWheelRaw.x + e.deltaX * 0.01)),
                Math.max(minY, Math.min(maxY, vec2MouseWheelRaw.y - e.deltaY * 0.01))
            );
        });

        /* adds paste support for Clipboard ImageBlob -> Three.js Texture */
        // window.doPasteFromClipboard = async function(){
        //     try{
        //         const items = await navigator.clipboard.read();
        //         console.warn('items',items)
        //         for (const item of items) {
        //             if (item.types.includes('image/png')) {
        //                 const blob = await item.getType('image/png');
        //                 const url = URL.createObjectURL(blob);
        //                 if(window?.inputTextureA?.image){
        //                     return;
        //                 }
        //                 window.inputTextureA.image.onload = function() {
        //                     URL.revokeObjectURL(url);
        //                     window.inputTextureA.needsUpdate = true;
        //                 };
        //                 window.inputTextureA.image.src = url;
        //                 break;
        //             }
        //             // or if ti's a base64 image in a text string, pass _that_ to image.src
        //             if (item.types.includes('text/plain')) {
        //                 const text = await item.getType('text/plain');
        //                 if(window?.inputTextureA?.image){
        //                     return;
        //                 }
        //                 window.inputTextureA.image.onload = function() {
        //                     URL.revokeObjectURL(url);
        //                     window.inputTextureA.needsUpdate = true;
        //                 };
        //                 window.inputTextureA.image.src = text;
        //                 break;
        //             }
        //         }
        //     }catch(e){
        //         console.error(e);
        //     }
        // }

        Object.defineProperty(window, "safePXDims", {
            get: function() {
                return {
                    x: Math.floor(window.pixelWidth / window.settings.pixel_density * dpr / 2) * 2,
                    y: Math.floor(window.pixelHeight / window.settings.pixel_density * dpr / 2) * 2
                }
            }
        });

        window.resetPingPong = function(){
            console.warn('resetPingPong',{
                safePXDims,
            })

            composer.swapBuffers();

            window.outputTextureA = new THREE.WebGLRenderTarget(safePXDims.x, safePXDims.y);
            window.outputTextureA.texture.magFilter = THREE.NearestFilter;
            window.outputTextureA.texture.minFilter = THREE.NearestFilter;
            window.outputTextureA.texture.wrapS = THREE.MirroredRepeatWrapping;
            window.outputTextureA.texture.wrapT = THREE.MirroredRepeatWrapping;
            // window.outputTextureA.depthTexture = new THREE.DepthTexture();
            // window.outputTextureA.depthTexture.type = THREE.FloatType;
            window.outputTextureA.needsUpdate = true;

            window.outputTextureB = new THREE.WebGLRenderTarget(safePXDims.x, safePXDims.y);
            window.outputTextureB.texture.magFilter = THREE.NearestFilter;
            window.outputTextureB.texture.minFilter = THREE.NearestFilter;
            window.outputTextureB.texture.wrapS = THREE.MirroredRepeatWrapping;
            window.outputTextureB.texture.wrapT = THREE.MirroredRepeatWrapping;
            // window.outputTextureB.depthTexture = new THREE.DepthTexture();
            // window.outputTextureB.depthTexture.type = THREE.FloatType;
            window.outputTextureB.needsUpdate = true;

            window._originalOutputTextureA = window.outputTextureA;
            window._originalOutputTextureB = window.outputTextureB;
        }

        window.updateMouseUniforms = function() {
            // Normalize coordinates (0 to 1)
            let normalizedX = window.mouseX / pixelWidth; //window.innerWidth;
            let normalizedY = window.mouseY / pixelHeight; //window.innerHeight;

            // Adjust for aspect ratio
            const aspect = window.innerWidth / window.innerHeight;
            if (aspect > 1) {
                // Wider than tall
                normalizedX = (normalizedX - 0.5) * aspect + 0.5;
            } else {
                // Taller than wide
                normalizedY = (normalizedY - 0.5) / aspect + 0.5;
            }

            // offset to center of "quad"
            normalizedX = normalizedX * 2 - 1;
            normalizedY = normalizedY * 2 - 1;

            // Set the shader uniform
            // Implement ShaderToy compatibility:
            // Shows how to use the mouse input (only left button supported):
            //      mouse.xy  = mouse position during last button down
            //  abs(mouse.zw) = mouse position during last button click
            // sign(mouse.z)  = button is down
            // sign(mouse.w)  = button is clicked

            // let dist = Math.sqrt(normalizedX * normalizedX + normalizedY * normalizedY);
            // let magnitude = Math.max(0.9,Math.min(dist, 2.0));
            // magnitude *= vec2MouseWheelLerped.y;
            
            window.mouseRaw.set(
                window.mouseX, 
                window.innerHeight - window.mouseY, 
                window.leftMouseDown ? 1 : -1, 
                0
            );
            window.mouseLerping.lerp(window.mouseRaw, window.settings.mouseLerpFactor);
            vec2MouseWheelLerped.lerp(vec2MouseWheelRaw, .08);
        }

        window.updateMaterialUniforms = function(material, uniforms){

            uniforms = {...{
                iTime: cumulativeTime,
                iResolution: new THREE.Vector3(safePXDims.x, safePXDims.y, 1.0),
                
                iMouseRaw: new THREE.Vector3(
                    window.mouseRaw.x, 
                    window.mouseRaw.y, 
                    window.mouseRaw.z, 
                    0
                ),
                iMouse: new THREE.Vector4(
                    window.mouseLerping.x, 
                    window.mouseLerping.y, 
                    window.leftMouseDown ? 1 : -1, 
                    0
                ),
                iMouseWheel: new THREE.Vector4(
                    vec2MouseWheelLerped.x, 
                    vec2MouseWheelLerped.y, 
                    vec2MouseWheelRaw.x, 
                    vec2MouseWheelRaw.y
                ),
                // maybe we do a mouse position heatmap offscreen buffer at somepoint
                iPrevMouse: new THREE.Vector4(
                    window.prevMousePosition.x, 
                    window.prevMousePosition.y, 
                    window.prevMousePosition.z, 
                    window.prevMousePosition.w
                ),

                // num_lights: {value:settings.num_lights},
                ambientLightColor: settings.ambientLightColor,
                decayColor: settings.decayColor,
                fxFloats: new THREE.Vector4(
                    settings.alphaShadow,
                    settings.mixNormals,
                    settings.clickMouseToDraw ? 1.0 : 0.0,
                    settings.num_lights
                ),
                fxFloats2: new THREE.Vector4(
                    settings.baseLineScaling,
                    //settings.baseLineOffset,
                    settings.hueShiftSpeed,
                    settings.hueShiftOffset,
                    0
                ),
            }, ...uniforms};

            // console.warn('setting uniforms',uniforms)

            Object
            .keys(uniforms)
            .forEach(function(key) {
                if(typeof uniforms[key] === 'undefined'){
                    console.warn("uniforms["+key+"] is undefined", uniforms);
                    return;
                }

                if(typeof material.uniforms[key] === 'undefined'){
                    console.warn("Material does not have a uniform named: " + key);
                    return;
                }

                // if(key === 'num_lights'){
                //     // console.log('setting num_lights',material.uniforms.num_lights,'<-',uniforms[key].value)
                //     material.uniforms.num_lights = uniforms[key].value; // parseFloat(uniforms[key]);
                //     return;
                // }

                if(key === 'fxFloats' || key === 'fxFloats2'){
                    // console.log('setting alphaShadow',uniforms[key])
                    material.uniforms[key].value = uniforms[key];
                    return;
                }

                // if it's a float, just set it
                if(typeof uniforms[key] === 'number' && typeof material.uniforms[key].value === 'number'){
                    material.uniforms[key].value = uniforms[key];
                    return;
                }

            if(key === 'iChannel0' || key === 'iChannel1' || key === 'iChannel2' || key === 'iChannel3'){
                    //console.warn('setting channel',key,uniforms[key])
                    material.uniforms[key].value = uniforms[key].texture;
                    return;
                }

                // rgba
            if(uniforms[key].hasOwnProperty('r') && uniforms[key].hasOwnProperty('g') && uniforms[key].hasOwnProperty('b') && uniforms[key].hasOwnProperty('a')){
                    //console.warn('setting color',key,uniforms[key])
                    material.uniforms[key].value = [
                        uniforms[key].r, 
                        uniforms[key].g, 
                        uniforms[key].b, 
                        uniforms[key].a
                    ];

                    return;
                }
                // rgb
            if(uniforms[key].hasOwnProperty('r') && uniforms[key].hasOwnProperty('g') && uniforms[key].hasOwnProperty('b')){
                    //console.warn('setting color',key,uniforms[key])
                    material.uniforms[key].value = [
                        uniforms[key].r, 
                        uniforms[key].g, 
                        uniforms[key].b
                    ];

                    return;
                }

            if (uniforms[key] instanceof THREE.Vector4) {
                    material.uniforms[key].value.set(
                        uniforms[key].x, 
                        uniforms[key].y, 
                        uniforms[key].z, 
                        uniforms[key].w
                    );

                    return;
                }if (uniforms[key] instanceof THREE.Vector3) {
                    material.uniforms[key].value.set(
                        uniforms[key].x, 
                        uniforms[key].y, 
                        uniforms[key].z
                    );

                    return;
                }if (uniforms[key] instanceof THREE.Vector2) {
                    material.uniforms[key].value.set(
                        uniforms[key].x, 
                        uniforms[key].y
                    );

                    return;
                }
                    console.warn('Unknown uniform type', key, uniforms[key]);
            });
            return material;
        }

        window.randomWalking = false;
        window.randomWalkTimeout = null;
        window.randomWalk_inner = function(){
            // pick a random delay
            let randomDelay = Math.floor(Math.random() * 500) + 10;
            // pick a random direction
            let randomDirection = {
                x: Math.random() < 0.5 ? -0.2 : 0.2,
                y: Math.random() < 0.5 ? -0.2 : 0.2,
                z: Math.random() < 0.5 ? -0.2 : 0.2,
            }
            let scalar = Math.random() * 1.5 + 0.1;
            randomDirection.x *= scalar;
            randomDirection.y *= scalar;
            randomDirection.z *= scalar;


            // bounce off the edges
            if(window.mouseX + randomDirection.x * window.safePXDims.x > window.pixelWidth || window.mouseX + randomDirection.x * window.safePXDims.x < 0){
                randomDirection.x *= -1;
            }
            if(window.mouseY + randomDirection.y * window.safePXDims.y > window.pixelHeight || window.mouseY + randomDirection.y * window.safePXDims.y < 0){
                randomDirection.y *= -1;
            }
            window.mouseX += randomDirection.x * window.safePXDims.x;
            window.mouseY += randomDirection.y * window.safePXDims.y;
            window.vec2MouseWheelRaw.y += randomDirection.z * 10;

            window.randomWalkTimeout = setTimeout(()=>{
                window.randomWalk_inner();
            }, randomDelay);
        }
        window.randomWalk = function() {
            if(window.randomWalking){
                window.randomWalking = false;
                clearTimeout(window.randomWalkTimeout);
                return;
            }
            window.randomWalking = true;
            window.randomWalk_inner();
        }

        window.setupMaterials = function(){
            let DEFAULT_UNIFORMS = {
                // compatibility uniforms
                // tDiffuse: { value: inputTextureA.texture },
                iTime: { value: 1.0 },
                iChannel0: { value: inputTextureA.texture },
                iChannel1: { value: inputTextureB.texture },
                //iChannel2: { value: normalTexture.texture },
                iChannel3: { value: userInputTexture.texture },


                // output buffer slot 1
                // iBuffer0: { value: outputTextureA.texture },
                // iBuffer1: { value: normalTexture.texture },

                iResolution: { value: new THREE.Vector3(0) },
                iPrevMouse: { value: new THREE.Vector4(0) },
                iMouse: { value: window.mouseLerping },
                iMouseRaw: { value: window.mouseRaw },
                iMouseWheel: { value: window.iMouseWheel },
                // num_lights: { value: settings.num_lights },
                fxFloats: { value: new THREE.Vector4(0) },
                fxFloats2: { value: new THREE.Vector4(0) },
                ambientLightColor: { value: settings.ambientLightColor },
                ambientLightColorAlpha: { value: settings.ambientLightColorAlpha },
                decayColor: { value: settings.decayColor },
                clickMouseToDraw: { value: settings.clickMouseToDraw }
            }   

            window.outputMaterialA = new THREE.ShaderMaterial({
                //glslVersion: THREE.GLSL3,
                uniforms: {
                    ...DEFAULT_UNIFORMS
                },
                vertexShader: `
                    void main() {
                        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
                    }
                `,
                fragmentShader: window.fragmentShaderSource,
                transparent: true, // Enable transparency
            });

            // do a SECOND material
            // tied to combineTexturesShaderSource
            window.outputMaterialB = new THREE.ShaderMaterial({
                //glslVersion: THREE.GLSL3,
                uniforms: {
                    ...DEFAULT_UNIFORMS
                },
                vertexShader: `
                    void main() {
                        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
                    }
                `,
                fragmentShader: window.combineTexturesShaderSource,
                transparent: true, // Enable transparency
            });
        }


        window.setupThree = async function(){
            const pasteFromClipboardPrompt = document.getElementById("pasteFromClipboardPrompt");
            function showPasteFromClipboardPrompt(){
                pasteFromClipboardPrompt.classList.add("show");
                setTimeout(()=>{
                    pasteFromClipboardPrompt.classList.remove("show");
                },5000);
            }
            function hidePasteFromClipboardPrompt(){
                pasteFromClipboardPrompt.classList.remove("show");
            }
            let didShowClipboardPrompt = false;
            let currentClipboardBagValueHash = null;
            let previousClipboardBagValueHash = null;
            // let clipboardCheckInterval = setInterval(async()=>{
            //     if(didShowClipboardPrompt){
            //         // check if clipboard has changed
            //         let currentClipboardBagValueHash = null;
            //         try{
            //             const items = await navigator.clipboard.read();
            //             let hash_string = '';
            //             for (const item of items) {
            //                 let types_concat = item.types.join('');
            //                 hash_string += types_concat;
            //                 hash_string += item.size ?? 0;
            //                 hash_string += item.lastModified ?? 0;
            //             }
            //             console.warn({hash_string})
            //             currentClipboardBagValueHash = hash_string;
            //         }catch(e){
            //             console.error(e);
            //         }
            //         if(currentClipboardBagValueHash != previousClipboardBagValueHash){
            //             didShowClipboardPrompt = false;
            //         }
            //     }

            //     if(didShowClipboardPrompt){
            //         return;
            //     }
            //     didShowClipboardPrompt = true;
            //     try{
            //         const text = await navigator.clipboard.readText();
            //         if(text){
            //             showPasteFromClipboardPrompt();
            //         }else{
            //             hidePasteFromClipboardPrompt();
            //             console.warn('nothing in clipboard')
            //         }
            //     }catch(e){
            //         console.error(e);
            //     }
            // },1000);
            
            
            document.addEventListener("keydown",(e)=>{
                if(e.key == "v" && (e.ctrlKey || e.metaKey)){
                    try{
                        // window.doPasteFromClipboard();
                        handleFileInput(e);
                    }catch(e){
                        console.error(e);
                    }
                }
            },false);

            document.getElementById("fileupload").addEventListener("change", (e) => {
                hideIntroText();
                handleFileInput(e);
            });
            canvas = document.getElementById("canvas");
            window.renderer = new THREE.WebGLRenderer({canvas, alpha: true});
            //renderer.setClearColor(0x000000, 1.0);
            renderer.autoClear = false;
            renderer.setPixelRatio( dpr );
            renderer.setSize( window.innerWidth, window.innerHeight );
				
            // 3. Enable WebXR in the renderer:
            renderer.xr.enabled = true;
            document.body.appendChild(VRButton.createButton(renderer));

            // "real" size, full screen
            canvas.width = pixelWidth;
            canvas.height = pixelHeight;
            // Scale up the canvas using CSS
            canvas.style.width = '100vw';
            canvas.style.height = '100vh';
            canvas.style.imageRendering = 'pixelated'; // This ensures nearest neighbor scaling in browsers that support it
            //canvas.style.imageRendering = 'crisp-edges'; // This ensures nearest neighbor scaling in browsers that support it

            //object-fit: contain;
            canvas.style.objectFit = 'contain';

            // Orthographic camera setup
            const frustumSize = 1;
            window.aspect = safePXDims.x / safePXDims.y; //canvas.clientWidth / canvas.clientHeight;
            window.camera = new THREE.OrthographicCamera(
                frustumSize * aspect / -2, 
                frustumSize * aspect / 2, 
                frustumSize / 2, 
                frustumSize / -2, 
                1, 
                500
            );
            camera.position.z = 1;

            window.scene = new THREE.Scene();

            window.composer = new EffectComposer(renderer);
            // disable auto clear
            // composer.autoClear = false;
            
            const renderPass = new RenderPass( scene, camera );
            composer.addPass( renderPass );

            

            

            // Full-screen plane geometry
            window.planeGeometry = new THREE.PlaneGeometry(2 * aspect, 2);

            window.textureLoader = new THREE.TextureLoader();

            let rand_int_1_thru_17 = Math.floor(Math.random() * 17) + 1;
            //let url = `./res/bg_${rand_int_1_thru_17}.png`;
            //let url = "./res/download (3).png";
            let url = "/starpages/res/inspiration/Bsodwindows10.png";
            window.inputTextureA = await textureLoader.loadAsync(url);
            window.inputTextureB = window.inputTextureA.clone(); // clone
            window.userInputTexture = window.inputTextureA.clone(); // clone

            // define our textures / buffers
            // 1. our starting values (provided by user image or video, etc)
            window.originalPixelDataTexture = new THREE.DataTexture(
                new Uint8Array(4 * fixedPixelsX * fixedPixelsY), 
                fixedPixelsX, 
                fixedPixelsY, 
                THREE.RGBAFormat, 
                THREE.UnsignedByteType
            );
            // 2. our target values
            window.targetPixelDataTexture = new THREE.DataTexture(
                new Uint8Array(4 * fixedPixelsX * fixedPixelsY), 
                fixedPixelsX, 
                fixedPixelsY, 
                THREE.RGBAFormat, 
                THREE.UnsignedByteType
            );
            // 3. our lerping output texture, which we use to lerp between the original and target textures
            // this is our output buffer for now, but we may add additional buffers later
            window.lerpedColorTexture = new THREE.DataTexture(
                new Uint8Array(4 * fixedPixelsX * fixedPixelsY), 
                fixedPixelsX, 
                fixedPixelsY, 
                THREE.RGBAFormat, 
                THREE.UnsignedByteType
            );
            // 4. our "offset" buffer where we accumulate / calculate our offsets
            window.offsetTexture = new THREE.DataTexture(
                new Uint8Array(4 * fixedPixelsX * fixedPixelsY), 
                fixedPixelsX, 
                fixedPixelsY, 
                THREE.RGBAFormat, 
                THREE.UnsignedByteType
            );

            resetPingPong();
            
            window.image_height = inputTextureA.height;
            window.image_width = inputTextureA.width;

            // Set how many times the texture should repeat
            // inputTextureA.repeat.set(2, 2); // Adjust as needed
            // inputTextureB.repeat.set(2, 2); // Adjust as needed

            /* Match ShaderToy uniforms for compatibility */
            // Custom Shader
            window.mouseRaw = new THREE.Vector4(window.innerWidth/2,window.innerHeight/2, 0, 0);
            window.mouseLerping = new THREE.Vector4(window.innerWidth/2,window.innerHeight/2, 0, 0);
            window.iMouseWheel = new THREE.Vector4(0, 10, 0, 0);

            // window.normalTexture = new THREE.WebGLRenderTarget(safePXDims.x, safePXDims.y);
            // window.normalTexture.texture.magFilter = THREE.NearestFilter;
            // window.normalTexture.texture.minFilter = THREE.NearestFilter;
            // window.normalTexture.texture.wrapS = THREE.MirroredRepeatWrapping;
            // window.normalTexture.texture.wrapT = THREE.MirroredRepeatWrapping;
            // window.normalTexture.needsUpdate = true;

            setupMaterials();
            // shaderPass.uniforms.iChannel0 = window.outputTextureA;
            outputMaterialB.uniforms.iChannel0.value = window.outputTextureA.texture;

            // window.passA = new ShaderPass(window.outputMaterialA);
            // passA.uniforms.iChannel0.value = outputTextureB.texture;

            // window.passB = new ShaderPass(window.outputMaterialB);
            // passB.uniforms.iChannel0.value = outputTextureA.texture;
            
            // Creating and adding the plane to the scene
            window.plane = new THREE.Mesh(planeGeometry, window.outputMaterialA);
            scene.add(plane);

            window.resizeRendererToDisplaySize = function() {
                canvas = window.renderer.domElement;
                // let width = pixelWidth ?? window.innerWidth;
                // let height = pixelHeight ?? window.innerHeight;

                // force to even dimensions for ffmpeg compatibility
                // width = 2 * Math.floor(width / 2);
                // height = 2 * Math.floor(height / 2);

                // const needResize = canvas.width !== width || canvas.height !== height;
                // if (needResize) {
                //     // apply settings.pixel_density
                //     width /= window.pixel_density;
                //     height /= window.pixel_density;
                //     // enforce even dimensions
                //     width = 2 * Math.floor(width / 2);
                //     height = 2 * Math.floor(height / 2);
                //     // update our pixel dimensions
                //     renderer.setSize(width, height, false);
                // }
                return false; // needResize;
            }

            window.mouseX = window.mouseY = 0;
            window.prevMousePosition = new THREE.Vector4(0,0,0,0);
            window.updatePrevMouse = function(){
                prevMousePosition = {
                    x: window.mouseX,
                    y: window.mouseY,
                    z: window.leftMouseDown ? 1 : -1,
                    w: 0
                }
            }
            document.addEventListener('mousemove', (e)=>{
                updatePrevMouse();
                window.mouseX = e.clientX;
                window.mouseY = e.clientY;
            });
            window.vec2MouseWheelRaw = new THREE.Vector2(0.0, 10.0);
            window.vec2MouseWheelLerped = new THREE.Vector2(0.0, 10.0);
            

            // Global variable to store the last played video
            let lastPlayedVideo = null;

            window.onVideoPause = function(){
                window.fixedTime = theVideoplayerElement.currentTime; //.uniforms.iTime.value;
                if(!window.capturing && !handling_slow_motion_advance){
                    window.videoIsPlaying = false;
                }
            }
            window.onVideoResume = function(){
                window.fixedTime = null;
                if(!window.capturing && !handling_slow_motion_advance){
                    window.videoIsPlaying = true;
                }
            }

            window.createVideoElement = function(){
                let video = document.createElement('video');
                video.setAttribute('id', 'video');
                video.crossOrigin = 'anonymous';
                video.loop = true;
                // Add an event listener for when the video ends
                //video.onended = pickOne;
                video.onpause = onVideoPause;
                video.onplay = onVideoResume;
                //video.muted = true;

                // min of the html attribute is 0.1, 
                // if we want to go lower, we need to simulate with pause and manual frame-stepping
                // see: window.targetVideoPlaybackRate
                video.playbackRate = 0.1; 

                video.pictureInPictureEnabled = true;
                video.addEventListener('enterpictureinpicture', (event) => {
                    console.warn('enterpictureinpicture',event)
                });
                video.addEventListener('leavepictureinpicture', (event) => {
                    console.warn('leavepictureinpicture',event)
                });
                // video.addEventListener('loadedmetadata', (event) => {
                //     console.warn('loadedmetadata',event)
                // });
                document.body.appendChild(video);
                window.theVideoplayerElement = video;
            }
            
            window.theVideoplayerElement = document.getElementById("video");
            if(!window.theVideoplayerElement){
                createVideoElement();
            }
            window.setVideoAsChannel = function(videoURL){
                try{
                    //console.warn('setVideoAsChannel',videoURL)
                    
                    let video = window.theVideoplayerElement;
                    
                    video.src = videoURL;
                    video.autoplay = false; // true;
                    video.controls = true;
                    video.buffer = true;
                    video.play();
                    let needs_on_can_play_update = true;
                    video.oncanplay = function() {
                        if(needs_on_can_play_update){
                            needs_on_can_play_update = false;
                            window.videoTexture = new THREE.VideoTexture(video);
                            window.videoTexture.minFilter = THREE.LinearFilter;
                            window.videoTexture.magFilter = THREE.LinearFilter;
                            window.videoTexture.format = THREE.RGBFormat;
                            window.videoTexture.crossOrigin = 'anonymous';
                            window.videoTexture.needsUpdate = true;

                            window.targetInputTexture = window.videoTexture;
                            window.userInputTexture = window.videoTexture;
                            window.inputTextureA = window.targetInputTexture;
                            window.inputTextureB = window.targetInputTexture;

                            try{
                                video.play();
                            }catch(e){
                                console.warn(e);
                            }
                            setTimeout(()=>{
                                window.videoIsPlaying = true;
                                window.videoIsVirtuallyPlaying = true;
                                resetPingPong();
                            },1);
                        }
                    }
                }catch(e){
                    console.error(e);
                }
            }

            window.progressElement = document.getElementById("progress");

            window.shaderPass = new ShaderPass(window.outputMaterialB, "iChannel0");
            composer.addPass( shaderPass );

            // // gamma correction
            // window.gammaCorrectionPass = new ShaderPass(GammaCorrectionShader);
            // console.warn(Object.keys(window.gammaCorrectionPass));
            // gammaCorrectionPass.renderToScreen = true;
            // //gammaCorrectionPass.uniforms["gamma"] = {value: 0.1}
            // composer.addPass( gammaCorrectionPass );


            // const ssaoPass = new SSAOPass( scene, camera, window.innerWidth, window.innerHeight );
            // composer.addPass( ssaoPass );

            // const vignettePass = new ShaderPass(VignetteShader);
            // vignettePass.uniforms["offset"].value = 0.95;
            // vignettePass.uniforms["darkness"].value = 1.6;
            // composer.addPass( vignettePass );

            // const effectPass = new EffectPass(camera, new BloomEffect());
            // composer.addPass( effectPass );

            // const bloomPass = new UnrealBloomPass();
            // composer.addPass( bloomPass );

            const outputPass = new OutputPass();
            composer.addPass( outputPass );

            resizeCanvas();
            resetPingPong();
            // first frame...
            requestAnimationFrame(animate);

            let did_react_to_first_user_input = false;
            let maybeFirstInput = ()=>{
                if(!did_react_to_first_user_input){
                    did_react_to_first_user_input = true;
                    //pickOne();

                    document.getElementsByTagName("video")?.[0]?.play();
                }
            }

            window.droppedOnAnything = function(e){
                console.warn('dropped on anything',e)
                did_react_to_first_user_input = true;
                e.preventDefault();
                e.stopPropagation();
                
                handleFileInput(e);
            }

            // when a user drops an image on the canvas, load it to our texture
            window.addEventListener('drop', droppedOnAnything);
            window.addEventListener('dragover', (e) => {
                //console.warn('dragover',e)
                e.preventDefault();
                e.stopPropagation();
            });

            

            

            document.addEventListener("keydown",async(e)=>{
                if(e.key == "Escape"){
                    hidePasteFromClipboardPrompt();
                }

                // if command v on mac,
                // or control v on other,
                // paste image from clipboard
                if ( 
                    (e.keyCode === 22 || e.keyCode === 86)
                    && (e.metaKey || e.ctrlKey)
                ){
                    await onPasteAttempt();
                    e.preventDefault();
                }

                maybeFirstInput();
            },false);
            // document.addEventListener("mouseup",()=>{
            //     maybeFirstInput();
            // });
            // document.addEventListener("dblclick",()=>{
            //     maybeFirstInput();
            // })
            // document.addEventListener("resize",()=>{
            //     canvas = document.getElementById("canvas");
            //     window.renderer = new THREE.WebGLRenderer({canvas,alpha:true});
            //     const width = canvas.clientWidth;
            //     const height = canvas.clientHeight;
            //     fixedPixelsX = safePXDims.x;
            //     fixedPixelsY = safePXDims.y;
            //     renderer.setSize(fixedPixelsX, pixedPixelsY, false);
            // })

            // fast start
            window.targetVideoPlaybackRate = 1.0; 
            hideIntroText(); 
            //window.setVideoAsChannel("./res/0006.mp4");
            // window.setImageAsChannel("../res/test/Sketchfab_UV_Checker.png");
        }

        
        window.hideWelcome = function(){
            document.querySelector(".intro-card").classList.toggle("fade-out",true);
            document.querySelector(".intro-underlay").classList.toggle("fade-out",true);
        }
        
        window.startCapture = function(){
            if(!window.capturer){
                console.warn("capturer not initialized");
                return;
            }
            
            window.subframePlaybackCurrentFrame = 0;
            window.capturing = true;
            window.capturer.start();
            // 0 = restart
            animate(0);
            //theVideoplayerElement.pause();
            window.currentVideoTime = video.currentTime = 0;
        }
        window.stopCapture = function(){
            if(!window.capturer){
                console.warn("capturer not initialized");
                return;
            }
            window.capturing = false;
            window.capturer.stop();
            window.capturer.save();
        }

        // fsshader fragment shader source frag shader here fshader

        // note: we've bound the outputSurfacePositionBuffer to the vertex shader's "aVertexPosition" attribute
        // we've bound the offset texture to the fragment shader's "uOffsetTexture" uniform
        // and, critically, we've bound the offset texture to texture unit 0 (gl.TEXTURE0)
        // currently, the vertex shader does nothing, since we need a highly subdivided mesh to see the effect of the offset texture
        // so for now, we're using a simple "pass-through" vertex shader, which simply passes the vertex position to the fragment shader

        let frameCount = 0;
        let seed = 0;
        let MODE = 1;
        let _max_step_sort_size = 1e5 * 2;
        // larger = LARGER pixels, smaller = smaller (FASTER, LOWER REZ), 1:1 pixel ratio (SLOWER, HIGH REZ)
        // let _pixel_density = 8; //4; 
        // Object.defineProperty(window, "pixel_density", {
        //     get: function(){
        //         return _pixel_density;
        //     },
        //     set: function(value){
        //         _pixel_density = value;
        //         resizeCanvas();
        //     }
        // });
        Object.defineProperty(window, "MAX_SORT_STEP_SIZE", {
            get: function(){
                return _max_step_sort_size; // Math.floor(canvas.width / pixel_density) * Math.floor(canvas.height / pixel_density);
            },
            set: function(value){
                _max_step_sort_size = value;
                current_sortStepSize = value;
                sortStepSize = value;
            }
        })

        //let then = 0;
        let uSwirlAmp = 1.0, uSwirlTurns = 3.0;
        
        let pixel_positions = [];
        let pixelData, originalPixelData, latestPixelDataSnapshot;
        const bytesPerPixel = 4; // For RGBA format

        window.recenterMouseRefValue = function(){
            mouseX=window.innerWidth/2;mouseY=window.innerHeight/2
        }

        window.prepareCCapture = function(){
            try{
                // Check if WebP is supported
                var isWebPSupported = document.createElement('canvas').toDataURL('image/webp').indexOf('data:image/webp') == 0;
                window.motionBlurFrames = 0;
                capturer = isWebPSupported 
                ? new CCapture( { 
                    format: 'webm', 
                    motionBlurFrames,
                    verbose: false, 
                    fps: window.targetRecordingFPS 
                } ) 
                : (()=>{
                    console.warn('webP not supported, using png :/')
                    return new CCapture( { 
                    format: 'png', 
                    motionBlurFrames,
                    verbose: false, 
                    framerate: window.targetRecordingFPS 
                    } )
                })();
            }catch(e){
                console.error('failed to create capturer',e);
            }
        }

        /** 
         * TODO: extend this with some of the functionality that was 
         * previously only in the onpasteattempt function:
        
                    // Check if the Clipboard API is available
                    if (!navigator.clipboard) {
                        console.warn('Clipboard API not available.');
                        throw new Error('Clipboard API not available');
                    }

                    // Attempt to read from the clipboard
                    const clipboardItems = await navigator.clipboard.read();
                    console.log('Clipboard items retrieved:', clipboardItems);

                    let clipboardBag = {images:[]};

                    // Find text content in clipboard items
                    const textItem = clipboardItems.find(item => item.types.includes('text/plain'));
                    if (textItem) {
                        const textBlob = await textItem.getType('text/plain');
                        const text = await textBlob.text();
                        console.log('Pasted text content: ', text);
                        clipboardBag.text = text;
                    }

                    // Find HTML content in clipboard items
                    const htmlItem = clipboardItems.find(item => item.types.includes('text/html'));
                    if (htmlItem) {
                        const htmlBlob = await htmlItem.getType('text/html');
                        const html = await htmlBlob.text();
                        console.log('Pasted HTML content: ', html);
                        clipboardBag.html = html;
                    }
                    // Note: imageBlob is an instance of Blob
                    // to get pixel data OUT of the blob and INTO 3D space, we need to load it as a texture
                    // to do THAT (we need to assume it could be a _local_ file so we _can not_ use the img.src shortcut,)
                    // we need to do the slow, full conversion of a Blob to a base64 encoded string
                    // then we can use that base64 encoded string to load the image as a texture
                    


                    // Find any "image" items:
                    const imageItems = clipboardItems.filter(item => item.types.includes('image/png'));
                    // Alert if there's multiple, we only support one for now
                    if (imageItems.length > 1) {
                        alert('Multiple images found. Using the last image.');
                    }
                    for (const imageItem of imageItems) {
                        const imageBlob = await imageItem.getType('image/png');
                        //console.log('Pasted image: ', image);
                        clipboardBag.imageBlob = imageBlob;

                        //loadImageBlobAsTexture(imageBlob);
                        
                        let b64 = await imageBlobToBase64(imageBlob);
                        //console.log('Pasted image: ', b64);

                        await loadBase64AsTexture(b64);
                        clipboardBag.images.push(b64);
                    }
        */
        async function handleFileInput(e) {
            let file;
            if (e.dataTransfer) { // Handle file drop event
                e.preventDefault();
                e.stopPropagation();
                if (e.dataTransfer.files && e.dataTransfer.files.length > 0) {
                    file = e.dataTransfer.files[0];
                }
            } else if (e.target.files) { // Handle file input change event
                file = e.target.files[0];
            }  else if (e.clipboardData) { // Handle paste event
                const clipboardItems = await navigator.clipboard.read();
                const imageItem = clipboardItems.find(item => item.types.includes('image/png'));
                if (imageItem) {
                    file = await imageItem.getType('image/png');
                }
            }

            if (file) {
                if (file.type.includes('video')) {
                    window.setVideoAsChannel(URL.createObjectURL(file));
                } else if (file.type.includes('image')) {
                    let url = URL.createObjectURL(file);
                    let img = new Image();
                    img.src = url;
                    img.onload = function() {
                        setImageAsChannel(url);
                    }
                } else if (file.type.includes('gif')) { // Added support for gif files
                    let url = URL.createObjectURL(file);
                    let img = new Image();
                    img.src = url;
                    img.onload = function() {
                        setImageAsChannel(url);
                    }
                }
            }
        }

        window.setImageAsChannel = async function(url){
            if(url.includes('.gif')){
                //window.setVideoAsChannel(url);
                //return;
                console.error('gifs not supported yet :/')
            }

            window.inputTextureA = await textureLoader.loadAsync(url);

            console.warn('setImageAsChannel',url,inputTextureA.image);

            if(window.inputTextureA?.image){
                // window.inputTextureA.image.src = url;
                window.inputTextureB.image = window.inputTextureA.image;

                // window.inputTextureA.needsUpdate = true;
                // window.inputTextureB.needsUpdate = true;
            }else{
                console.warn('no inputTextureA.image!')
            }

            resetPingPong();

            // update our originalPixelDataTexture (Three.js Texture)
            window.originalPixelDataTexture.image = window.inputTextureA.image;
            window.originalPixelDataTexture.needsUpdate = true;

            window.userInputTexture = window.inputTextureA.clone();
            window.targetInputTexture = window.userInputTexture;
        }

        window.settings = {
            timeScale: 1,
            pixel_density: 1,
            
            useDoubleBuffer: true,
            ambientLightColor: {r:0.5,g:0.0,b:1.0,a:0.5},
            ambientLightColorAlpha: 0.02,
            num_lights: 0.999,
            alphaShadow: 0.9,
            decayColorAlpha: 0.001,
            mixNormals: 0,
            radius: 10.0,
            decayColor: {r: 1.0, g: 0.0, b: 0.0, a: 0.01},

            clickMouseToDraw: false,

            baseLineScaling: 0.0,

            mouseLerpFactor: 0.1, // 0.1

            hueShiftSpeed: 0.0,
            hueShiftOffset: 0.0,
        }

        window.randomizeSettings = function(){
            settings.ambientLightColor.r = Math.random();
            settings.ambientLightColor.g = Math.random();
            settings.ambientLightColor.b = Math.random();
            settings.ambientLightColor.a = Math.random();
            settings.ambientLightColorAlpha = Math.random();
            settings.num_lights = Math.random();
            settings.alphaShadow = Math.random();
            settings.decayColorAlpha = Math.random();
            settings.mixNormals = Math.random();
            settings.radius = Math.random();
            settings.decayColor.r = Math.random();
            settings.decayColor.g = Math.random();
            settings.decayColor.b = Math.random();
            settings.decayColor.a = Math.random();
            settings.baseLineScaling = Math.random();
            settings.mouseLerpFactor = Math.random();
        }

        window.onSettingsChanged = function(){
            console.warn('todo: jog shader data');
        }

        let cumulativeTime = 0;
        let frameStart = 0;
        let startedAt;
        let frame = 0;
        window.animate = function(time) {
            canvas = renderer.domElement;
            if(!startedAt){
                startedAt = performance.now();
            }

            let now = performance.now();
            let diff = now - frameStart;
            diff /= 1000;
            frameStart = now;
            let _time = window.fixedTime ? window.fixedTime : time;
            // if(!window.fixedTime){
                cumulativeTime += diff;
            // }else{
            //     cumulativeTime = _time;
            // }

            // Update uniforms
            updateMouseUniforms();
            
            // _Really_ we only have to update _one_ per frame i think...
            updateMaterialUniforms(window.outputMaterialA, {
                iChannel0: window.outputTextureA,
                iChannel1: window.inputTextureB,
                iChannel3: window.userInputTexture,
            });
            window.outputMaterialA.uniformsNeedUpdate = true;
            updateMaterialUniforms(window.outputMaterialB, {
                iChannel0: window.outputTextureA,
                iChannel1: window.outputTextureB,
                iChannel3: window.userInputTexture,
            });
            window.outputMaterialB.uniformsNeedUpdate = true;

            

            // if(settings.useDoubleBuffer){
            //     try{
            //         plane.material = window.outputMaterialA;
            //         window.outputMaterialA.uniforms.iChannel0.value = window.outputTextureB.texture;
            //         window.outputMaterialA.uniformsNeedUpdate = true;
            //         renderer.setRenderTarget(window.outputTextureA);
            //         renderer.render(scene, camera);
            //         window.outputTextureA.needsUpdate = true;
            //         // // Use the rendered texture as input for the next pass
            //         // window.outputMaterialB.uniforms.iChannel0.value = window.outputTextureA.texture;
            //         // window.outputMaterialB.uniformsNeedUpdate = true;

            //         // // now render that to a texture
            //         // renderer.setRenderTarget(window.outputTextureB);
            //         // renderer.render(scene, camera);

            //         // window.outputTextureB.needsUpdate = true;

            //     }catch(e){
            //         console.error(e);
            //     }
            // }
            
            // plane.material = window.outputMaterialB;
            // window.outputMaterialB.uniforms.iChannel0.value = window.outputTextureA.texture;
            // window.outputMaterialB.uniforms.iChannel1.value = window.outputTextureB.texture;
            // window.outputMaterialB.uniformsNeedUpdate = true;
            // Reset render target back to the canvas
            // renderer.setRenderTarget(null);
            renderer.render(scene, camera);

            // if(settings.useDoubleBuffer){
            //     // continually swap the textures (ping-pong buffer trade's off read/write duty)
            //     let tempA = window.outputTextureA;
            //     window.outputTextureA = window.outputTextureB;
            //     window.outputTextureB = tempA;
            //     window.outputMaterialA.uniforms.iChannel0.value = window.outputTextureA.texture;
            //     window.outputMaterialB.uniforms.iChannel0.value = window.outputTextureA.texture;
            //     window.outputMaterialA.uniformsNeedUpdate = true;
            //     window.outputMaterialB.uniformsNeedUpdate = true;
            // }else{
            //     // keep them the same
            //     // noop
            // }

            if(window.capturing){
                window.currentFrameDelta = targetRecordingFPS / 1000;
                // update recording progress
                if (progressElement) {
                    // Calculate progress based on targetRecordingDurationSeconds
                    progressElement.value = (window.subframePlaybackCurrentFrame / maxFrames) * 100;
                }
                window.capturer.capture(canvas);
                
                if(window.subframePlaybackCurrentFrame >= maxFrames){
                    window.stopCapture();
                }else{
                    // emulate being called requestAnimationFrame with a DOMHighResTimeStamp
                    setTimeout(() => {
                        window.animate(_time + window.currentFrameDelta);
                    }, 0);
                }
            }else{
                window.currentFrameDelta = performance.now() - frameStart;
                // next frame
                requestAnimationFrame(animate);
                // Render to targetA in even frames, targetB in odd frames
                // composer.renderTarget1 = frame % 2 === 0 ? outputTextureA : outputTextureB;
                // composer.renderTarget2 = frame % 2 === 0 ? outputTextureB : outputTextureA;

                // console.warn('composer pass len', composer.passes.length);

                // Swap passes
                // let temp = composer.passes[1];
                // composer.passes[1] = composer.passes[2];
                // composer.passes[2] = temp;

                // outputMaterialB.uniforms.iChannel0.value = outputTextureA.texture;

                composer.render();

                frame++;
            }
        }

        // Function to parse the hash from URL
        function getHashSettings() {
            const hash = window.location.hash.substring(1);
            const settings = {};
            hash.split('&').forEach(part => {
                const item = part.split('=');
                settings[item[0]] = decodeURIComponent(item[1]);
            });
            return settings;
        }

        function getSettingsAsHash(){
            const _settings = JSON.parse(JSON.stringify(settings));
            delete _settings.useDoubleBuffer;
            //delete _settings.pixel_density;
            return Object.keys(_settings).map(key => `${key}=${encodeURIComponent(_settings[key].value || _settings[key])}`).join('&');
        }

        // Function to update URL hash
        function updateHash(controller) {
            const hashSettings = getSettingsAsHash();
            hashSettings[controller.property] = controller.getValue();
            const newHash = Object.keys(hashSettings).map(key => `${key}=${encodeURIComponent(hashSettings[key])}`).join('&');
            window.location.hash = newHash;
        }

        // Generic change handler function
        function handleChange() {
            const values = {};
            Object.keys(gui.__controllers).forEach(key => {
                const controller = gui.__controllers[key];
                values[controller.property] = controller.getValue();
            });
            updateHash(this);
        }

        window.lastMouseMoveWasFake = false;

        window.setupPanel = function () {
            if(!window.panel){
                window.panel = new lil.GUI();
                window.panel.close();
                //console.warn('window.setupPanel, panel not ready yet');
                //return;
            }
            
            panel.add(settings, 'radius', 0.1, 100.0, 0.1)
                .name( 'Radius' )
                .onChange((value) => {
                    vec2MouseWheelRaw.y = Math.max(-100, Math.min(value, 100));
                });

            panel.add(settings, 'pixel_density', 0.00001, 32, 0.00001)
                .name( 'Pixel Density' )
                .onChange( window.resizeCanvas );

            panel.add(settings, 'num_lights', 0, 1, .3)
                .name( 'Num Lights #️⃣💡' )
                .onChange(value => {
                    window.settings.num_lights = value;
                })
        
            panel.add(settings, 'alphaShadow', 0, 1, 0.01)
                .name( 'Alpha Shadow' )

            panel.add(settings, 'baseLineScaling', -2, 2, 0.01)
                .name( 'Base Line Scaling' )
                .onChange((value)=>{
                    window.settings.baseLineScaling = value;
                })

            // ambientLightColor
            panel.addColor(settings, 'ambientLightColor', true)
                .name('Ambient Light Color')
                .onChange((value)=>{
                    window.settings.ambientLightColor = value
                });
            // ambientLightColorAlpha
            panel.add(settings, 'ambientLightColorAlpha', 0.01, 1, 0.01)
                .name('Ambient Light Color Alpha')
                .onChange((value)=>{
                    window.settings.ambientLightColor.a = value;
                });

            // decayColor
            panel.addColor(settings, 'decayColor')
                .name('Decay Color')
                .onChange((value)=>{
                    window.settings.decayColor = value
                });
            panel.add(settings, 'decayColorAlpha', 0, .1, 0.0001)
                .name( 'Decay Color Alpha' )
                .onChange((value)=>{
                    window.settings.decayColor.a = Math.pow(value,2);
                });

            panel.add(settings, 'mixNormals', 0, 1, 0.01)
                .name('Show Normal Map')
                .onChange((value)=>{
                    settings.mixNormals = value;
                    // console.warn('mix normal map', value);
                });

            panel.add(settings, 'mouseLerpFactor', 0, 1, 0.01)
                .name("Lerp Factor")

            panel.add(settings, 'clickMouseToDraw')
                .name("Press To Draw")
                .onChange((value)=>{
                    settings.clickMouseToDraw = value;
                });
            
            // add a boolean checkbox for settings.useDoubleBuffer
            // panel.add(settings, 'useDoubleBuffer')
            //     .name('Use Double Buffer')
            //     .onChange((value)=>{
            //         settings.useDoubleBuffer = value;
            //         console.warn('use double buffer', value);
            //     });
            
            // panel add a button called "resizeCanvas"
            // panel.add({ resizeCanvas: function() { window.resizeCanvas(); } }, 'resizeCanvas');
            
            panel.add({ resetPingPong: window.resetPingPong }, 'resetPingPong')
                .name('[c] clear buffer')

            // Hue Shift Speed
            // Hue Shift Offset
            panel.add(settings, 'hueShiftSpeed', 0, 1, 0.01)
                .name('Hue Shift Speed')
                .onChange((value)=>{
                    settings.hueShiftSpeed = value;
                });
            panel.add(settings, 'hueShiftOffset', 0, 1, 0.01)
                .name('Hue Shift Offset')
                .onChange((value)=>{
                    settings.hueShiftOffset = value;
                });

            // panel.add({ toggleBigSweep: function() { window.toggleBigSweep(); } }, 'toggleBigSweep');
            // toggleJiggleSwirl
            // panel.add({ toggleJiggleSwirl: function() { window.toggleJiggleSwirl(); } }, 'toggleJiggleSwirl');

            // Lastly
            // Apply the change handler to all controllers
            // panel.__controllers.forEach(controller => {
            //     controller.onChange(handleChange);
            // });

            window.addEventListener('keydown', (e)=>{
                if(e.key === 'c' || e.key === 'C'
                ){
                    window.resetPingPong();
                }
                if(e.key === 'r' || e.key === 'R'){
                    window.randomWalk();
                }
                if(e.key === 'q' || e.key === 'Q'){
                    window.vec2MouseWheelRaw.y += 10;
                    settings.radius = Math.max(-100, Math.min(window.vec2MouseWheelRaw.y, 100));
                }
                if(e.key === 'a' || e.key === 'A'){
                    window.vec2MouseWheelRaw.y -= 10;
                    settings.radius = Math.max(-100, Math.min(window.vec2MouseWheelRaw.y, 100));
                }
                if(e.key === 'w' || e.key === 'W'){
                    window.vec2MouseWheelRaw.y = 10;
                    settings.radius = Math.max(-100, Math.min(window.vec2MouseWheelRaw.y, 100));
                }
                console.warn(e.key);
                // arrows drive iMouseRaw
                if(e.key === 'ArrowUp'){
                    lastMouseMoveWasFake = true;
                    window.mouseY -= 10;
                }
                if(e.key === 'ArrowDown'){
                    lastMouseMoveWasFake = true;
                    window.mouseY += 10;
                }
                if(e.key === 'ArrowLeft'){
                    lastMouseMoveWasFake = true;
                    window.mouseX -= 10;
                }
                if(e.key === 'ArrowRight'){
                    lastMouseMoveWasFake = true;
                    window.mouseX += 10;
                }
            });

            panel.add({
                toggleFullscreen: function() {
                    if (document.fullscreenElement) {
                        document.exitFullscreen();
                    } else {
                        document.documentElement.requestFullscreen();
                    }
                }
            }, 'toggleFullscreen').name('[f] fullscreen');

            // panel.add({
            //     toggleSlowMotion: function() {
            //         window.toggleSlowMotion();
            //     }
            // }, 'toggleSlowMotion').name('[s] slow motion');

            panel.add({
                randomWalk: function() {
                    window.randomWalk();
                }
            }, 'randomWalk').name('[r] random walk');

            // panel.add( settings, 'res', 1, 6, 1 )
            //     .name( 'Res' )
            //     .onFinishChange( compile );

            // panel.add( settings, 'bounds', 1, 10, 1 )
            //     .name( 'Bounds' )
            //     .onFinishChange( compile );

            // panel.add( settings, 'material', [ 'depth', 'normal' ] )
            //     .name( 'Material' ).onChange( setMaterial );

            // panel.add( settings, 'wireframe' )
            //     .name( 'Wireframe' ).onChange( setMaterial );

            // panel.add( settings, 'autoRotate' )
            //     .name( 'Auto Rotate' );

            // panel.add( settings, 'vertexCount' )
                // .name( 'Vertex count' ).listen().disable();
        }

        // domready
        async function onReady(){

            

            setupPanel();

            // if(!confirm('this demo produces flashing lights, are you sure you want to continue?')){
            //     return;
            // }
            window.fragmentShaderSource = await (await fetch("/starpages/shaders/fresh.glsl")).text();
            //  window.fragmentShaderSource = await (await fetch("../shaders/uber-shader.glsl")).text();
            // window.fragmentShaderSource = await (await fetch("../shaders/frosted-video-mandlebulb.glsl")).text();
            // window.fragmentShaderSource = await (await fetch("../shaders/simple-ripple.glsl")).text();
            window.combineTexturesShaderSource = await (await fetch("/starpages/shaders/combine.glsl")).text();
            prepareCCapture();
            setupThree();
        }

        document.addEventListener("resize", ()=>{
            // onResize
            resizeCanvas();
            // todo: they sould grow and shrink dynamically...
            initializePositionsAndOffsetData(keepPixelData = true);
        });

        // resizeCanvas = function
        function resizeCanvas() {



            window.pixelWidth = window.innerWidth;
            window.pixelHeight = window.innerHeight;
            // force to even dimensions for ffmpeg compatibility
            let width = 2 * Math.floor(pixelWidth / 2);
            let height = 2 * Math.floor(pixelHeight / 2);
            canvas.width = width;
            canvas.height = height;
            fixedPixelsX = safePXDims.x; // Math.floor(canvas.width/settings.pixel_density);
            fixedPixelsY = safePXDims.y; //.floor(canvas.height/settings.pixel_density);
            console.warn('resizeCanvas',pixelWidth,pixelHeight,'->',fixedPixelsX,fixedPixelsY)

            // update our pixel dimensions
            renderer.setSize(width, height, false);

            camera.aspect = canvas.width / canvas.height;
            camera.updateProjectionMatrix();

            // update our iResolution uniforms
            // TODO: allow different resolutions per "layer"
            if(window.outputMaterialA?.uniforms){
                window.outputMaterialA.uniforms.iResolution.value.set(fixedPixelsX, fixedPixelsY, settings.pixel_density);
            }else{
                console.warn('no outputMaterialA.uniforms')
            }
            if(window.outputMaterialB?.uniforms){
                window.outputMaterialB.uniforms.iResolution.value.set(fixedPixelsX, fixedPixelsY, settings.pixel_density);
            }else{
                console.warn('no outputMaterialB.uniforms')
            }
        }

        // two triangles that cover the entire screen
        // our display surface positions, not our inner "pixel" positions
        const output_surface_positions = [
            -1, -1,
            1, -1,
            -1, 1,
            -1, 1,
            1, -1,
            1, 1,
        ];

        // CPU outputSurfacePositionBuffer (output_surface_positions) mirrors to the GPU "offset texture":
        // these "positional" offsets are used as "Target" x, y values
        // and the fragment shader uses these "target" values, 
        // and lerps the "current" value _towards_ 
        // the "target" value over a parameterized duration of time
        // offsetTexture: [screenWidth x screenHeight] (rgba); where r = x offset, and g = y offset | b,a are unused for now

        // we artificially delay the sorting algo. to help visualize the sorting process
        // we then show how parallelism can be used to speed up the sorting process (bitonic sort) + realtime "accumulation" of the sorted values (similar to Raytracing stochastic accumulation)
        let numPixels = 0;
        let fixedPixelsX,fixedPixelsY;
        function initializePositionsAndOffsetData(keepPixelData = true) {
            numPixels = fixedPixelsX * fixedPixelsY; // canvas.width * canvas.height;
            //numPixels = Math.floor(numPixels / settings.pixel_density);

            if(!keepPixelData){
                pixel_positions = [];
                pixelData = undefined;
            }

            // if `pixel_positions` is empty or undefined, we need to initialize it
            // otherwise, we need to determine to grow or shrink it
            if(typeof pixel_positions === "undefined" || !pixel_positions.length){
                pixel_positions = new Float32Array(numPixels * 2); // x, y for each pixel
            }else{
                // shrink || grow
                // if we're shrinking, we need to truncate the array
                // if we're growing, we need to pad the array
                if(pixel_positions.length > numPixels * 2){
                    // truncate
                    pixel_positions = pixel_positions.slice(0,numPixels * 2);
                }else if(pixel_positions.length < numPixels * 2){
                    // pad
                    let new_pixel_positions = new Float32Array(numPixels * 2);
                    new_pixel_positions.set(pixel_positions);
                    pixel_positions = new_pixel_positions;
                }
            }

            resetOffsetTexture();
            if(typeof pixelData === "undefined" || !pixelData.length){
                pixelData = new Uint8Array(numPixels * bytesPerPixel); // RGBA for each pixel

                // Initialize position and pixel data
                for (let y = 0; y < fixedPixelsY; y++) {
                    for (let x = 0; x < fixedPixelsX; x++) {
                        const index = (y * fixedPixelsX + x) * 2;
                        const pixelIndex = (y * fixedPixelsX + x) * bytesPerPixel;

                        // Set position (x, y)
                        pixel_positions[index] = (x / fixedPixelsX) * 2 - 1; // Convert to clip space
                        pixel_positions[index + 1] = (y / fixedPixelsY) * 2 - 1; // Convert to clip space

                        // Initialize pixel data with random colors
                        pixelData[pixelIndex] = Math.floor(Math.random() * 256); // R
                        pixelData[pixelIndex + 1] = Math.floor(Math.random() * 256); // G
                        pixelData[pixelIndex + 2] = Math.floor(Math.random() * 256); // B
                        pixelData[pixelIndex + 3] = Math.floor(Math.random() * 256); // Alpha
                    }
                }
            }else{
                // grow or shrink pixelData
                if(pixelData.length > numPixels * bytesPerPixel){
                    // truncate
                    pixelData = pixelData.slice(0,numPixels * bytesPerPixel);
                }else if(pixelData.length < numPixels * bytesPerPixel){
                    // pad
                    let new_pixelData = new Uint8Array(numPixels * bytesPerPixel);
                    new_pixelData.set(pixelData);
                    pixelData = new_pixelData;
                }
            }
        }

        function rgbToHsv(color){
            let r = color[0] / 255;
            let g = color[1] / 255;
            let b = color[2] / 255;
            let max = Math.max(r, g, b), min = Math.min(r, g, b);
            let h, s, v = max;
        
            let d = max - min;
            s = max == 0 ? 0 : d / max;
        
            if (max == min) {
                h = 0; // achromatic
            } else {
                switch (max) {
                    case r: h = (g - b) / d + (g < b ? 6 : 0); break;
                    case g: h = (b - r) / d + 2; break;
                    case b: h = (r - g) / d + 4; break;
                }
        
                h /= 6;
            }
        
            return [ h, s, v ];
        }

        let swapped = false;
        let DID_COMPLETE_SORT_SINCE_RESET = false;
        // current sorting offset
        // we pass this to our fragment shader 
        // so we can color the pixels that are currently being sorted
        // we also pass the window width, so we can color the pixels that are being compared
        let sortOffset = 0;
        window.sortStepSize = 10e5; //-1; //10e3; // Number of elements to sort per call, adjust as needed
        window.current_sortStepSize = window.sortStepSize;

        window.resetOffsetTexture = function(erasePixelData = false){
            // reset offset texture to all 0s with 255 for alpha channel
            let zeros = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
            zeros = zeros.map((value, index) => {
                if (index === 3) {
                    return 255;
                }
                return value;
            });

            // TODO!!! replace these two with THREE.js corresponding calls
            // gl.bindTexture(gl.TEXTURE_2D, offsetTexture);
            // gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, fixedPixelsX, fixedPixelsY, 0, gl.RGBA, gl.UNSIGNED_BYTE, zeros);

            if(erasePixelData){
                // reset pixel data to all 0s
                pixelData = new Uint8Array(fixedPixelsX * fixedPixelsY * bytesPerPixel);
            }
        }

        function newCheck(inner_i, currentColor, currentHSV, nextColor, nextHSV){
            let swapped = 0;
            let rankA = 0; // should we swap?
            let rankB = 0;
            rankA += currentHSV[0] > nextHSV[0] ? 1 : 0;
            rankB += currentHSV[0] < nextHSV[0] ? 1 : 0;

            rankA += currentHSV[1] > nextHSV[1] ? 1 : 0;
            rankB += currentHSV[1] < nextHSV[1] ? 1 : 0;

            rankA += currentHSV[2] > nextHSV[2] ? 1 : 0;
            rankB += currentHSV[2] < nextHSV[2] ? 1 : 0;

            rankA *= currentColor[3]/255; // account for alpha
            rankB *= nextColor[3]/255; // account for alpha

            //console.warn({rankA,rankB})

            // old:
            //if(rankA > rankB){

            // new: epsilon-based approach
            if(rankA > rankB + Math.random()*0.001){
                // Swap colors in pixel data
                [pixelData[inner_i * bytesPerPixel], pixelData[(inner_i + 1) * bytesPerPixel]] = [pixelData[(inner_i + 1) * bytesPerPixel], pixelData[inner_i * bytesPerPixel]];
                [pixelData[inner_i * bytesPerPixel + 1], pixelData[(inner_i + 1) * bytesPerPixel + 1]] = [pixelData[(inner_i + 1) * bytesPerPixel + 1], pixelData[inner_i * bytesPerPixel + 1]];
                [pixelData[inner_i * bytesPerPixel + 2], pixelData[(inner_i + 1) * bytesPerPixel + 2]] = [pixelData[(inner_i + 1) * bytesPerPixel + 2], pixelData[inner_i * bytesPerPixel + 2]];

                // NOTE: we don't swap, we're going to just update our pixelData using r to represent x offset, and g to represent y offset
                // we'll use the fragment shader to do the actual swapping
                // use our fixedPixelsX to account for row/column wrapping in this x/y calculation
                // we're visually how far the pixel has moved in terms of 1D array indexes, from it's original position to it's sorted position over time
                // we're going to be additively writing incremental changes as brightness adjustments to the offset texture
                // negative when we need to move left/up, positive when we need to move right/down
                // keeping in mind that we're accounting for going from 1D array space to 2D screen space as though the array were laid out in a rasterized pattern
                let x_offset = (inner_i + 1) % fixedPixelsX - inner_i % fixedPixelsX;
                let y_offset = Math.floor((inner_i + 1) / fixedPixelsX) - Math.floor(inner_i / fixedPixelsX);

                // make the offset a fixed value from 0 - 0.1
                x_offset = Math.sign(x_offset) * 0.1;
                y_offset = Math.sign(y_offset) * 0.1;

                // NOTE: given how array shifting works, we need to "write" an additive value to the offset texture for each intermediary pixel between the two pixels we're swapping
                // nice thing about this algo is, it's bitwise, so we can do it in parallel, AND there's no interviening pixels, so we don't have to account for it with our current sort algo
                pixelData[inner_i * bytesPerPixel] += x_offset;
                pixelData[inner_i * bytesPerPixel + 1] += y_offset;
                // empty green channel
                pixelData[inner_i * bytesPerPixel + 2] = 0;

                swapped = true;
            }
            return swapped;
        }

        let noSwapStreak = 0; // Track consecutive passes without swaps
        let prevDidSwap = false; // Track whether a swap occurred in the previous pass

        function finalSortPass() {
            sortStepSize = 1; // Set window size to minimum
            applyBubbleSortStep(); // Perform final sort pass
        }

        function isOverlookingPixels() {
            // Implement logic to check for consistently overlooked pixels
            // This could be a heuristic based on tracking which pixels haven't moved in several passes
            // or it could be a heuristic based on the number of pixels that have moved in the last pass
            
            return false; // Placeholder return
        }

        /** 
         * return true if swapped
         * */
        function applyBubbleSortStep() {
            //console.warn("Applying bubble sort step");
            // Apply one step of the bubble sort algorithm
            swapped = false;

            let crossedCycleBoundaryThisPass = false;

            const numPixels = fixedPixelsX * fixedPixelsY;
            let _sortStepSize = window.sortStepSize === -1 ? numPixels : window.sortStepSize;

            if (window.sortStepSize === -1) {
                let scale;
                if (numPixels < 1e5) {
                    // do multiple passes per frame when the image is small enough to fit into a single pass
                    scale = 1e5 / numPixels;
                } else {
                    // break into smaller chunks for large images
                    scale = numPixels / 1e5;
                }
                _sortStepSize = numPixels * scale; // Adjusting for pixel density
            }
            window.current_sortStepSize = _sortStepSize;
            
            // if _sortStepSize is > than the size of threads on our GPU, we need to break it up into multiple passes

            // Calculate the end of the current sorting window
            //const windowEnd = Math.min(sortOffset + _sortStepSize, numPixels - 1);
            const windowEnd = Math.max(0, sortOffset + _sortStepSize);

            // NOTE: there's a bug where if the offset is too large, we always wrap around before reaching the end of the base texture
            // we need to detect when this might happen and apply a correction to the window size to make sure that the whole texture is sorted
            // NOTE sortOffset is dynamic, and windowEnd is dynamic, so,
            // our heuristic to check if we might've overlooked pixels is defined as:
            // 

            // Update the sorting offset
            sortOffset += _sortStepSize;
            crossedCycleBoundaryThisPass = false;
            if (sortOffset >= numPixels) {
                crossedCycleBoundaryThisPass = true;
                // wrap around
                sortOffset = sortOffset % numPixels;
                // if we didnt swap this pass, 
                if(!prevDidSwap && !swapped){
                    // note we attribute multiple passes without swaps to the same cycle
                    noSwapStreak += Math.floor(((sortOffset % numPixels) / numPixels));
                }
            }

            for (let i = sortOffset; i < windowEnd - 1; i++) {
                let inner_i = i
                // if inner_i has gone out of bounds, we need to wrap it around
                if(inner_i >= numPixels){
                    inner_i = inner_i % numPixels;
                }
                const currentColor = pixelData.subarray(inner_i * bytesPerPixel, (inner_i + 1) * bytesPerPixel);
                const nextColor = pixelData.subarray((inner_i + 1) * bytesPerPixel, (inner_i + 2) * bytesPerPixel);

                let a_larger = (
                    currentColor[0] 
                    + currentColor[1] 
                    + currentColor[2] 
                    > 
                    nextColor[0] 
                    + nextColor[1] 
                    + nextColor[2]
                ) ? 1 : 0;

                if(window.reverseSort){
                    a_larger = !a_larger;
                }

                // Compare colors based on the sum of RGB values
                if (
                    a_larger
                ) {
                    // Swap colors in pixel data
                    [pixelData[inner_i * bytesPerPixel], pixelData[(inner_i + 1) * bytesPerPixel]] = [pixelData[(inner_i + 1) * bytesPerPixel], pixelData[inner_i * bytesPerPixel]];
                    [pixelData[inner_i * bytesPerPixel + 1], pixelData[(inner_i + 1) * bytesPerPixel + 1]] = [pixelData[(inner_i + 1) * bytesPerPixel + 1], pixelData[inner_i * bytesPerPixel + 1]];
                    [pixelData[inner_i * bytesPerPixel + 2], pixelData[(inner_i + 1) * bytesPerPixel + 2]] = [pixelData[(inner_i + 1) * bytesPerPixel + 2], pixelData[inner_i * bytesPerPixel + 2]];
                    swapped = true;
                }

                // convert to hsb , sort by hue, then value, then saturation
                // const currentHSV = rgbToHsv(currentColor);
                // const nextHSV = rgbToHsv(nextColor);
                // if(newCheck(inner_i, currentColor, currentHSV, nextColor, nextHSV)){
                //     swapped = true;
                // }
            }

            
            
            if (swapped) {
                // If a swap occurred, update the texture
                window.inputTextureA.needsUpdate = true;
                window.offsetTexture.needsUpdate = true;
                window.targetPixelDataTexture.needsUpdate = true;
                // TODO: determine which bounding box DID change, and only update that region...
                window.inputTextureA.image.data.set(pixelData);
            }

            // if we've somehow gone negative, flip positive and clamp to 0
            if(sortOffset < 0){
                throw new Error("sortOffset is negative");
            }

            prevDidSwap = swapped;

            return swapped;
        }

        /** @deprecating - STILL REFERENCING - DO NOT REMOVE YET - **/
        /*
        function render(now) {
            const deltaTime = now - then;
            then = now;
            tickBigSweep();

            //if (deltaTime > 0){//0.001) {
            if(do_sort){
                const swapped = applyBubbleSortStep();
                // if(
                //     noSwapStreak > 0 
                //     && !DID_COMPLETE_SORT_SINCE_RESET 
                //     && window.sortStepSize <= 2
                // ){
                //     DID_COMPLETE_SORT_SINCE_RESET = true;
                // }else{
                    if(
                        noSwapStreak > 0 // did we make it a full cycle with no swaps?
                        && !DID_COMPLETE_SORT_SINCE_RESET 
                        && window.sortStepSize > 2
                    ){
                        // let's start confirming by decreasing our sortStepSize
                        // reduce sortStepSize by factor of 2
                        window.sortStepSize = Math.max(2,parseInt(window.sortStepSize / 2));
                        console.warn('decreasing sortStepSize',window.sortStepSize);
                        if(window.sortStepSize <= 4){
                            // run our final sort pass
                            console.warn('final sort pass!')
                            DID_COMPLETE_SORT_SINCE_RESET = true;
                            finalSortPass();
                        }
                    }
                    if(
                        // if noSwapStreak reset, and we haven't completed the sort since the last reset
                        // and our current sortStepSize is less than our MAX_SORT_STEP_SIZE
                        // we increase the sortStepSize by factor of 2
                        noSwapStreak === 0 
                        && !DID_COMPLETE_SORT_SINCE_RESET 
                        && window.sortStepSize < window.MAX_SORT_STEP_SIZE
                    ){
                        // increase sortStepSize
                        window.sortStepSize = Math.min(window.MAX_SORT_STEP_SIZE,parseInt(window.sortStepSize * 2));
                        console.warn('increasing sortStepSize',window.sortStepSize,{
                            max: window.MAX_SORT_STEP_SIZE,
                        });
                    }
                //}
            }
            //}
        }
        */

        window.uScrollOffsetYSpeed = 0.05;
        window.uScrollOffsetXSpeed = -0.05;

        // window.bigSweepActive = false, window.bigSweepInterval = 0;
        // window.sweepFactor = 0.1;
        // window.tickBigSweep = function() {
        //     if (window.bigSweepActive) {
        //         window.mouseX = (Math.sin(Date.now() * 0.001) + 1) * ((window.innerWidth / 2) * window.sweepFactor);
        //         window.mouseY = (Math.cos(Date.now() * 0.001) + 1) * ((window.innerHeight / 2) * window.sweepFactor);
        //     }
        // }
        // window.toggleBigSweep = function(){
        //     window.bigSweepActive = !window.bigSweepActive;
        //     console.warn("window.bigSweepActive",window.bigSweepActive);   
        // }

        // window.jiggleSwirl = false;
        // window.swirlFreq = 1;
        // window.swirlMax = 1;
        // window.toggleJiggleSwirl = function(){
        //     window.jiggleSwirl = !window.jiggleSwirl;
        //     console.warn("window.jiggleSwirl",window.jiggleSwirl);

        //     clearInterval(window.mouseJiggler); 
        //     if(window.jiggleSwirl){
        //         window.mouseJiggler = setInterval(
        //             ()=>{
        //                 window.mouseX = (Math.sin(Date.now()*window.swirlFreq*0.0015) * window.swirlMax*256)
        //             },16)
        //     }
        // }
        
        document.addEventListener('DOMContentLoaded', async () => {
            let imageElement = document.getElementById('image'); // Assuming there's an img element with id 'image'
            // create if not exist
            if(!imageElement){
                imageElement = document.createElement('img');
                imageElement.id = 'image';
                imageElement.style.display = 'none';
                document.body.appendChild(imageElement);
            }

            
        });
        function createImageBitmap(imageBlob){
            return new Promise((resolve,reject)=>{
                // let imageElement = document.getElementById('image'); // Assuming there's an img element with id 'image'
                // // create if not exist
                // if(!imageElement){
                //     imageElement = document.createElement('img');
                //     imageElement.id = 'image';
                //     imageElement.style.display = 'none';
                //     document.body.appendChild(imageElement);
                // }
                // imageElement.onload = function(e){
                //     // once we can read the image, we can forward it to our shader...
                //     resolve(imageElement);
                // }
                let _image = new Image();
                _image.onload = function(e){
                    // once we can read the image, we can forward it to our shader...
                    resolve(_image);
                }
                imageElement.src = URL.createObjectURL(imageBlob);
            });
        }
        async function onPasteAttempt(e){
            try {
                handleFileInput(e);
                hideIntroText()

            } catch (error) {
                console.error('Error accessing clipboard:', error);
                // Handle error appropriately
            }
        }
        function hideIntroText(){
            canvas.classList.add('unblur');
            let match = document.getElementsByClassName('drop-here-text');
            if (match.length > 0) {
                Array.from(match).forEach((el) => {
                    el.classList.add('fadeout');
                });
            }
        }
        function showIntroText(skipBlur=false){
            if(!skipBlur){
                canvas.classList.remove('unblur');
            }
            let match = document.getElementsByClassName('drop-here-text');
            if (match.length > 0) {
                Array.from(match).forEach((el) => {
                    el.style.display = 'block';
                });
            }
        }
        document.addEventListener('keydown',async(e)=>{
            // if command v on mac,
            // or control v on other,
            // paste image from clipboard
            if ( 
                (e.keyCode === 22 || e.keyCode === 86)
                && (e.metaKey || e.ctrlKey)
            ){
                await onPasteAttempt(e);
            }
        },false)


        let startTouchesDistance = 0;
        document.addEventListener('touchmove',async(e)=>{
            mouseX = e.touches[0].clientX;
            mouseY = e.touches[0].clientY;
            lastMouseMoveWasFake = false;
            if(e.touches.length > 1) {
                let currentTouchesDistance = Math.hypot(
                    e.touches[0].clientX - e.touches[1].clientX,
                    e.touches[0].clientY - e.touches[1].clientY
                );
                vec2MouseWheelRaw.y = startTouchesDistance - currentTouchesDistance;
                startTouchesDistance = currentTouchesDistance;
            }
        })
        document.addEventListener('touchstart',async(e)=>{
            mouseX = e.touches[0].clientX;
            mouseY = e.touches[0].clientY;
            if(e.touches.length > 1) {
                startTouchesDistance = Math.hypot(
                    e.touches[0].clientX - e.touches[1].clientX,
                    e.touches[0].clientY - e.touches[1].clientY
                );
            }
        })

        // Mobile double-tap detection
        let doubleTapDetected = false;
        let doubleTapTimeout = null;
        const doubleTapDelay = 300;

        window.leftMouseDown = false;

        // uniform "double-tap"/double-click detection

        function checkDoubleTapDetected(){
            if (doubleTapDetected) {
                // Reset
                doubleTapDetected = false;
                clearTimeout(doubleTapTimeout);
                doubleTapTimeout = null;
                
                // showIntroText();
                // // update url
                // let uri = "https://jakedowns.com/media/0006.mp4";
                // window.videoTexture.image.src = uri;
                // window.videoTexture.needsUpdate = true;

                //inputTextureB = window.videoTexture;
            } else {
                doubleTapDetected = true;
                doubleTapTimeout = setTimeout(() => {
                    // Actions to perform if not a double tap
                    // Currently, it's set to perform the same actions, 
                    // but you can change this to suit your needs.

                    // Reset double tap detection
                    doubleTapDetected = false;
                    doubleTapTimeout = null;
                }, doubleTapDelay);
            }
        }
        document.addEventListener('dblclick', (e) => {
            checkDoubleTapDetected();
        }, false);

        document.addEventListener('touchend', (e) => {
            checkDoubleTapDetected();
        }, false);
        var num_modes = 5;
        document.addEventListener('click', (e)=>{
            MODE = (MODE + 1) % num_modes;
            // console.log("MODE",MODE);
            
            checkDoubleTapDetected();

            window.mouseRaw.set(
                window.mouseX, 
                window.innerHeight - window.mouseY, 
                window.leftMouseDown ? 1 : -1, 
                0
            );
            window.mouseLerping.copy(window.mouseRaw)
            

            // if(!window.do_sort){
            //     window.do_sort = true;
            //     console.log("do_sort",window.do_sort);
            // }
        });
        window.mouseX = window.mouseY = 0;
        document.addEventListener('mousemove', (e)=>{
            window.mouseX = e.clientX;
            window.mouseY = e.clientY;
            lastMouseMoveWasFake = false;
        });
        document.addEventListener('mousedown', (e)=>{
            window.leftMouseDown = e.button === 0;
            window.middleMouseDown = e.button === 1;
            window.rightMouseDown = e.button === 2;
            // window.mouse_btn_3 = e.button === 3;
            // window.mouse_btn_4 = e.button === 4;
            // window.mouse_btn_5 = e.button === 5;
            window.anyMouseDown = true;
        });
        document.addEventListener('mouseup', (e)=>{
            window.anyMouseDown = false;
            window.leftMouseDown = false;
            window.middleMouseDown = false;
            window.rightMouseDown = false;
        });
        function imageBlobToBase64(imageBlob){
            return new Promise((resolve,reject)=>{
                let reader = new FileReader();
                reader.onload = function(e){
                    resolve(e.target.result);
                }
                reader.readAsDataURL(imageBlob);
            });
        }
        
    document.addEventListener("DOMContentLoaded", function() {
        onReady();
        setTimeout(function() {
            var script = document.createElement('script');
            script.src = "https://www.googletagmanager.com/gtag/js?id=G-GYK2ZMX0M9";
            script.async = true;
            document.body.appendChild(script);

            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-GYK2ZMX0M9');

            // stats.js
            var script=document.createElement('script');script.onload=function(){
            var stats=new Stats();
            document.body.appendChild(stats.dom);
            stats.dom.style.position = 'absolute';
            stats.dom.style.bottom = '0px';
            stats.dom.style.top = 'auto';
            requestAnimationFrame(function loop(){stats.update();requestAnimationFrame(loop)});};
            script.src='https://mrdoob.github.io/stats.js/build/stats.min.js';
            document.head.appendChild(script);
        }, 10000);
    });
</script>
</body>
</html>
